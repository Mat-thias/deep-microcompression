{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df77885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    AvgPool2d,\n",
    "    BatchNorm2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    ReLU6,\n",
    "    MaxPool2d,\n",
    "    Flatten, \n",
    "\n",
    "    EarlyStopper,\n",
    "    quantize_per_tensor_assy,\n",
    "    quantize_per_tensor_sy,\n",
    "    dequantize_per_tensor_assy,\n",
    "    dequantize_per_tensor_sy,\n",
    "    \n",
    "    QuantizationGranularity,\n",
    "    QuantizationScaleType,\n",
    "    QuantizationScheme\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bf3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = f\"lenet5_state_dict_{DEVICE}.pth\"\n",
    "log_compression_details_file = \"lenet5_compression_log.csv\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 28, 28)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize(input_shape[1:]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"../../../Datasets/\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"../../../Datasets/\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32, shuffle=False, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=tuple([2]*4), bias=False),\n",
    "    # BatchNorm2d(num_features=6),\n",
    "    ReLU6(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    # BatchNorm2d(num_features=16),\n",
    "    ReLU(),\n",
    "    # ReLU6(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "    # AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Linear(in_features=16*5*5, out_features=84, bias=False),\n",
    "    ReLU6(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f8fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=5, pad=[2]*4, bias=True),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Conv2d(in_channels=6, out_channels=3, kernel_size=1, stride=1, pad=[0]*4, bias=False),\n",
    "#     MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*3*3, out_features=84, bias=False),\n",
    "#     ReLU(),\n",
    "#     Linear(in_features=84, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b811aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=5, pad=[2]*4, bias=False),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*6*6, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True), strict=True)\n",
    "    \n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-7,\n",
    "        mode=\"min\",\n",
    "        patience=2,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 2, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\" : accuracy_fun},\n",
    "        callbacks=[early_stopper],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 82.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.33\n",
      "The original model accuracy is 99.33% with size 148064 bytes.\n",
      "tensor([[-10.5499,  -3.5355,   9.8397,  -3.2319,  -9.1715, -12.8788,  -4.4893,\n",
      "           0.5832,  -4.2970,  -7.2553]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9933, 148064)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(original_acc*100)\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n",
    "print(lenet5_mcu_model.test(device=DEVICE))\n",
    "original_acc, original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc3f894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7ad091945820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3978d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.7500 size =    0.4235   99.5765\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.2700 size =    6.4384   93.5616\n",
      "0.5 QuantizationScheme.STATIC None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.8400 size =   25.0135   74.9865\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 20.5200 size =    1.4413   98.5587\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.7800 size =   21.4130   78.5870\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 35.0400 size =    2.3470   97.6530\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:06<00:00, 48.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.6300 size =   16.5827   83.4173\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 26.6000 size =   25.0000   75.0000\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 62.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.1500 size =    0.0648   99.9352\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 27.2700 size =    4.6784   95.3216\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 97.5200 size =    8.2924   91.7076\n",
      "0.3 QuantizationScheme.STATIC None 4\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 65.8900 size =    9.7120   90.2880\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 66.7400 size =    9.7120   90.2880\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 52.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.3000 size =    0.2121   99.7879\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 95.0000 size =   13.4651   86.5349\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.DYNAMIC None None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 12.5800 size =    0.2121   99.7879\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 35.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.7200 size =    0.0473   99.9527\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 64.6200 size =    4.8695   95.1305\n",
      "0.7 QuantizationScheme.STATIC None 4\n",
      "0.0 QuantizationScheme.STATIC None 8\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 52.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.6300 size =    0.7206   99.2794\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.6100 size =   10.7001   89.2999\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    6.2642   93.7358\n",
      "0.2 QuantizationScheme.DYNAMIC None 8\n",
      "0.5 QuantizationScheme.STATIC None 8\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 18.4100 size =    0.7341   99.2659\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 10.6000 size =    0.0338   99.9662\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 18.0200 size =    3.3675   96.6325\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 37.8700 size =    3.2263   96.7737\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 25.2700 size =    1.2920   98.7080\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.7200 size =   21.4130   78.5870\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.3700 size =   16.5827   83.4173\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.4 QuantizationScheme.DYNAMIC None 8\n",
      "0.9 QuantizationScheme.STATIC None None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1081   99.8919\n",
      "0.2 QuantizationScheme.NONE None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 98.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.NONE, granularity = None, bitwidth = None acc = 97.5700 size =   66.3308   33.6692\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3675   96.6325\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.6500 size =   10.7001   89.2999\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 41.9500 size =    3.2128   96.7872\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.DYNAMIC None None\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 17.2900 size =    2.3335   97.6665\n",
      "0.8 QuantizationScheme.DYNAMIC None 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 66.5700 size =    4.8695   95.1305\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6477   99.3523\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 13.4300 size =    2.5833   97.4167\n",
      "0.9 QuantizationScheme.STATIC None 8\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.6202   98.3798\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 57.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.9700 size =    0.4235   99.5765\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:11<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 22.2400 size =    1.3055   98.6945\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 38.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 70.7500 size =    4.8560   95.1440\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.4000 size =    0.2121   99.7879\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 53.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 25.0800 size =    1.2920   98.7080\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 31.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 35.9400 size =    2.3470   97.6530\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 21.2600 size =    1.4548   98.5452\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 93.7300 size =    8.3059   91.6941\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 96.9400 size =   16.5962   83.4038\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.9100 size =   21.3995   78.6005\n",
      "0.6 QuantizationScheme.DYNAMIC None 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.8500 size =   21.4130   78.5870\n",
      "0.2 QuantizationScheme.STATIC None 2\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "1.0 QuantizationScheme.STATIC None 2\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.4 QuantizationScheme.DYNAMIC None 8\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 62.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 70.8600 size =    4.8560   95.1440\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 94.7200 size =   13.4651   86.5349\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 36.8600 size =    3.2263   96.7737\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    6.2507   93.7493\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 19.7900 size =    0.7341   99.2659\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 65.8500 size =    4.8695   95.1305\n",
      "0.7 QuantizationScheme.DYNAMIC None 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 8.0600 size =    4.6649   95.3351\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.3000 size =   25.0000   75.0000\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.2000 size =    0.2121   99.7879\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    2.4429   97.5571\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.0700 size =   25.0135   74.9865\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.6500 size =    6.4384   93.5616\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.1812   98.8188\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 87.5500 size =    6.7464   93.2536\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 44.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 51.7600 size =    8.2924   91.7076\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 QuantizationScheme.DYNAMIC None 8\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.DYNAMIC None 8\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 13.1700 size =    2.5833   97.4167\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.4600 size =   16.5827   83.4173\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.4600 size =   16.5827   83.4173\n",
      "0.0 QuantizationScheme.NONE None 4\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 20.5000 size =    0.2256   99.7744\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 10.6500 size =    0.0338   99.9662\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.0324   99.9676\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 24.6900 size =    1.2920   98.7080\n",
      "0.5 QuantizationScheme.DYNAMIC None 2\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.3500 size =   12.5000   87.5000\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    5.3511   94.6489\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.6 QuantizationScheme.DYNAMIC None 4\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1081   99.8919\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1610   95.8390\n",
      "0.5 QuantizationScheme.DYNAMIC None None\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.1800 size =    0.2256   99.7744\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 93.7700 size =    6.7329   93.2671\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 96.8200 size =   16.5962   83.4038\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 22.5300 size =   16.5827   83.4173\n",
      "0.1 QuantizationScheme.STATIC None 8\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6612   99.3388\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 42.1700 size =    3.2128   96.7872\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.8400 size =    0.4370   99.5630\n",
      "0.7 QuantizationScheme.NONE None 4\n",
      "0.5 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 96.3700 size =   12.5135   87.4865\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 92.5200 size =   13.4786   86.5214\n",
      "0.1 QuantizationScheme.DYNAMIC None 8\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    5.3511   94.6489\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    2.4429   97.5571\n",
      "0.6 QuantizationScheme.NONE None 4\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 38.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 9.8000 size =    0.3613   99.6387\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 9.4400 size =    0.4235   99.5765\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.2900 size =   25.0000   75.0000\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 60.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 70.4200 size =    4.8560   95.1440\n",
      "0.7 QuantizationScheme.STATIC None 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3810   96.6190\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 41.0400 size =    3.2128   96.7872\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.4900 size =    0.2121   99.7879\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 60.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.3800 size =   16.5827   83.4173\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 13.2500 size =    2.5833   97.4167\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 30.6900 size =    4.6649   95.3351\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 39.0800 size =    3.2263   96.7737\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL None\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.1700 size =    0.0783   99.9217\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 25.2300 size =    4.8560   95.1440\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 52.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.1677   98.8323\n",
      "0.8 QuantizationScheme.STATIC None 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 71.1000 size =    4.8560   95.1440\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1216   99.8784\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 21.4900 size =    1.4548   98.5452\n",
      "1.0 QuantizationScheme.DYNAMIC None 8\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.5200 size =   12.5000   87.5000\n",
      "0.0 QuantizationScheme.DYNAMIC None None\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.DYNAMIC None 8\n",
      "0.5 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 5.9600 size =    0.0648   99.9352\n",
      "0.7 QuantizationScheme.DYNAMIC None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.0189   99.9811\n",
      "0.2 QuantizationScheme.DYNAMIC None 8\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.8300 size =    0.4235   99.5765\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC None None\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 95.1300 size =   13.4651   86.5349\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.1 QuantizationScheme.STATIC None 2\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 12.9700 size =    0.0648   99.9352\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.6300 size =   16.5827   83.4173\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 36.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 11.8300 size =    6.4249   93.5751\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 62.4800 size =    9.7255   90.2745\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.STATIC None 4\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 36.0000 size =    6.4384   93.5616\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 31.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.5700 size =    0.2256   99.7744\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:06<00:00, 44.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 9.1400 size =    0.4235   99.5765\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.7700 size =   21.4130   78.5870\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "1.0 QuantizationScheme.DYNAMIC None 8\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.6067   98.3933\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 58.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.0800 size =    0.2121   99.7879\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 12.9700 size =    0.0648   99.9352\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1610   95.8390\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 53.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 39.2000 size =    6.4249   93.5751\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 38.8200 size =    3.2263   96.7737\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 66.1400 size =    4.8695   95.1305\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.2 QuantizationScheme.NONE None 8\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1081   99.8919\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 30.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 14.9000 size =    0.4370   99.5630\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 55.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 97.1800 size =    8.2924   91.7076\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.2200 size =   25.0000   75.0000\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 35.5800 size =    3.2263   96.7737\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 9.8000 size =    0.0189   99.9811\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 20.3000 size =    0.2256   99.7744\n",
      "0.2 QuantizationScheme.STATIC None 8\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 38.2400 size =    3.2263   96.7737\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.0100 size =   21.3995   78.6005\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.0400 size =   25.0135   74.9865\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 88.9800 size =    6.7464   93.2536\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "1.0 QuantizationScheme.STATIC None 4\n",
      "0.6 QuantizationScheme.STATIC None 4\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 30.9800 size =    4.6649   95.3351\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 37.1200 size =    3.2263   96.7737\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1475   95.8525\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 87.8900 size =    6.7464   93.2536\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 QuantizationScheme.DYNAMIC None 8\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3810   96.6190\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 13.4300 size =    0.2121   99.7879\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 96.5400 size =   12.5135   87.4865\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 31.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 22.1500 size =    1.3055   98.6945\n",
      "0.1 QuantizationScheme.STATIC None 4\n",
      "0.5 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.9 QuantizationScheme.STATIC None 8\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 34.5200 size =    2.3470   97.6530\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 34.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1610   95.8390\n",
      "1.0 QuantizationScheme.STATIC None 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 18.7900 size =    0.7341   99.2659\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 65.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.3000 size =    0.7206   99.2794\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6612   99.3388\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 37.9600 size =    3.2263   96.7737\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1475   95.8525\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.8 QuantizationScheme.STATIC None 8\n",
      "0.8 QuantizationScheme.NONE None 2\n",
      "0.0 QuantizationScheme.DYNAMIC None None\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.1 QuantizationScheme.DYNAMIC None 2\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 20.9600 size =    1.4413   98.5587\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 60.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.7300 size =   16.5827   83.4173\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 30.8900 size =    4.6649   95.3351\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 24.8200 size =    4.8560   95.1440\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.3613   99.6387\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 31.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.2700 size =    6.4384   93.5616\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.DYNAMIC None 4\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 22.5300 size =   16.5827   83.4173\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.9700 size =    6.4384   93.5616\n",
      "0.8 QuantizationScheme.STATIC None 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 24.6400 size =    1.2920   98.7080\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:06<00:00, 48.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 10.6300 size =    0.0338   99.9662\n",
      "0.0 QuantizationScheme.NONE None 8\n",
      "0.5 QuantizationScheme.STATIC None None\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 31.1000 size =    4.6649   95.3351\n",
      "1.0 QuantizationScheme.DYNAMIC None 8\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 49.5600 size =    6.7329   93.2671\n",
      "0.6 QuantizationScheme.DYNAMIC None 8\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 9.7500 size =    0.6477   99.3523\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.6300 size =    0.4235   99.5765\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 31.0600 size =    4.6649   95.3351\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "1.0 QuantizationScheme.NONE None 8\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.0 QuantizationScheme.NONE None 4\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 27.0300 size =    4.6784   95.3216\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 62/313 [00:02<00:06, 38.08it/s]"
     ]
    }
   ],
   "source": [
    "sp = .1\n",
    "s = QuantizationScheme.DYNAMIC\n",
    "g = QuantizationGranularity.PER_TENSOR\n",
    "b = 4\n",
    "\n",
    "# for i in range(0, 11):\n",
    "#     sp = i/10\n",
    "\n",
    "# for i in [8, 4, 2]:\n",
    "\n",
    "#     b = i\n",
    "\n",
    "RANGE = 10\n",
    "for i in range(1000):\n",
    "    sp = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    s = random.choice([QuantizationScheme.NONE, QuantizationScheme.DYNAMIC, QuantizationScheme.DYNAMIC, QuantizationScheme.STATIC, QuantizationScheme.STATIC])\n",
    "    g = random.choice([None, QuantizationGranularity.PER_CHANNEL, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_TENSOR])\n",
    "    b = random.choice([None, 2, 4, 4, 8, 8])\n",
    "\n",
    "    print(sp, s, g, b)\n",
    "    compression_config = {\n",
    "        \n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : sp,\n",
    "            \"metric\" : \"l2\"\n",
    "        },\n",
    "\n",
    "        \"quantize\" : {\n",
    "            \"scheme\" : s,\n",
    "            \"granularity\": g,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "        # compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    # lenet5_mcu_model.cpu()\n",
    "    try:\n",
    "        compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    except ValueError:\n",
    "        continue\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "    # # compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "    # print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "    # print(\"#\"*40, \"Training\", \"#\"*40)\n",
    "    # early_stopper = EarlyStopper(\n",
    "    #     metric_name=\"validation_acc\",\n",
    "    #     min_valid_diff=.001,\n",
    "    #     mode=\"min\",\n",
    "    #     patience=3,\n",
    "    #     restore_best_state_dict=True,\n",
    "    # )\n",
    "\n",
    "    # criterion_fun = nn.CrossEntropyLoss()\n",
    "    # # optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    # compressed_lenet5_mcu_model.fit(\n",
    "    #     mnist_train_loader, \n",
    "    #     15, \n",
    "    #     criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    #     validation_dataloader=mnist_test_loader, \n",
    "    #     metrics={\"acc\": accuracy_fun},\n",
    "    #     verbose = True,\n",
    "    #     device=DEVICE,\n",
    "    #     callbacks = [early_stopper]\n",
    "    # )\n",
    "    # after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    # print(f\"After training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {after_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 92.59it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input_scale * weight_scale).view(1, -1, 1, 1)\n",
    "input_scale * weight_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d73749",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'compress'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      5\u001b[39m compression_config = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprune_channel\u001b[39m\u001b[33m\"\u001b[39m :{\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msparsity\u001b[39m\u001b[33m\"\u001b[39m : s\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m lenet5_mcu_model.cpu()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m compressed_lenet5_mcu_model = \u001b[43mlenet5_mcu_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompress\u001b[49m(compression_config, input_shape=input_shape, input_batch_real=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(mnist_test_loader))[\u001b[32m0\u001b[39m])\n\u001b[32m     18\u001b[39m compressed_lenet5_mcu_model.to(DEVICE)\n\u001b[32m     20\u001b[39m before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*\u001b[32m100\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'compress'"
     ]
    }
   ],
   "source": [
    "s = 0.5\n",
    "q = 3\n",
    "b = 8\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    # \"quantization\" : {\n",
    "    #     \"type\" : q,\n",
    "    #     \"bitwidth\" : b\n",
    "    # }\n",
    "\n",
    "}\n",
    "\n",
    "lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "s = 0.5\n",
    "q = 3\n",
    "b = 4\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    \"quantization\" : {\n",
    "        \"type\" : q,\n",
    "        \"bitwidth\" : b\n",
    "    }\n",
    "}\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = compressed_lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e02d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2343fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -4.2995,  -2.2290,  -1.3500,   7.7069,  -1.1915,  -1.9620, -12.2104,\n",
       "           -2.9040,  -1.8079,  -1.4910]], device='cuda:0'),\n",
       " tensor([[-1,  0,  0,  4,  0,  0, -5,  0,  0,  0]], device='cuda:0',\n",
       "        dtype=torch.int8))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model.test(device=DEVICE), \\\n",
    "quantize_per_tensor_assy(\n",
    "    compressed_lenet5_mcu_model.test(device=DEVICE),\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c44390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv2d_0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "  (relu6_0): ReLU6()\n",
       "  (maxpool2d_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_1): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu_0): ReLU()\n",
       "  (maxpool2d_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten_0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_0): Linear(in_features=400, out_features=84, bias=False)\n",
       "  (relu6_1): ReLU6()\n",
       "  (linear_1): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c49992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 28, 28])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], grad_fn=<SliceBackward0>)\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3]], dtype=torch.int8)\n",
      "torch.Size([1, 6, 14, 14])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=torch.int8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3, dtype=torch.int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model.cpu()\n",
    "test_input = compressed_lenet5_mcu_model.test_input.clone()\n",
    "\n",
    "test_input_quant = quantize_per_tensor_assy(\n",
    "    test_input,\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"],\n",
    ")\n",
    "\n",
    "test_input_real = dequantize_per_tensor_assy(\n",
    "    test_input_quant, \n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    ")\n",
    "\n",
    "i = 0\n",
    "# print(\"original real\", test_input[0,0,i])\n",
    "# print(\"quant real\", test_input_real[0,0,i])\n",
    "# print(\"quant\", test_input_quant[0,0,i])\n",
    "# line = torch.clamp(test_input[0,0,i]/compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"] + \\\n",
    "#                    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], -128, 127)\n",
    "# print(line)\n",
    "# print((line- compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]) * compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"])\n",
    "\n",
    "\n",
    "conv0 = compressed_lenet5_mcu_model[0]\n",
    "test_input_real = conv0(test_input_real)\n",
    "\n",
    "relu0 = compressed_lenet5_mcu_model[1]\n",
    "test_input_real = relu0(test_input_real)\n",
    "i = 5*2\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i:i+2])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i:i+2]\n",
    ")\n",
    "avgpool_0 = compressed_lenet5_mcu_model[2]\n",
    "test_input_real = avgpool_0(test_input_real)\n",
    "\n",
    "# flatten0 = compressed_lenet5_mcu_model[2]\n",
    "# test_input_real = flatten0(test_input_real)\n",
    "\n",
    "# linear0 = compressed_lenet5_mcu_model[3]\n",
    "# test_input_real = linear0(test_input_real)\n",
    "\n",
    "next_layer = compressed_lenet5_mcu_model[0]\n",
    "\n",
    "i = 5\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i]\n",
    ")\n",
    "\n",
    "# pad_input = nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     )\n",
    "# pad_weight = quant_weight.to(torch.int32)\n",
    "\n",
    "# quant_weight = quantize_per_tensor_sy(\n",
    "#         conv0.weight, \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#     )\n",
    "# test_input_quant = nn.functional.conv2d(\n",
    "#     nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     ),\n",
    "#     quant_weight.to(torch.int32),\n",
    "#     stride=5,\n",
    "# )\n",
    "\n",
    "# print(test_input_quant)\n",
    "# print(test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"])\n",
    "\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(test_input_real)\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_real,\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     nn.functional.conv2d(\n",
    "#         test_input_real, \n",
    "#         dequantize_per_tensor_sy(\n",
    "#             quant_weight,\n",
    "#                 conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#             ),\n",
    "#         stride=5\n",
    "#         # quantize_per_tensor_sy(\n",
    "#         #     conv0.weight, \n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#         # ).to(torch.int32),\n",
    "#         # stride=5,\n",
    "#     )\n",
    "\n",
    "# )\n",
    "# next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66a75c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1965599166.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msparsity_per_layer = 0.25\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " sparsity_per_layer = 0.25\n",
    "RANGE = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(log_compression_details_file):\n",
    "    with open(log_compression_details_file, \"w\") as file:\n",
    "        file.write(f\"sparsity, quantization_type, bitwidth, size, size_ratio, before acc, after acc, before acc_drop, after acc_drop\\n\")\n",
    "        # file.write(f\"sparsity, quantizaion_type, bitwidth, before acc, after acc\\n\")\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    # s = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    # q = random.choice([QUANTIZATION_NONE, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR])\n",
    "    # b = random.choice([4, 8])\n",
    "    # print(f\"sample number {i} ->  sparsity = {s}, q_type = {q}, bitwidth = {b}\")\n",
    "\n",
    "    s = 0.\n",
    "    q = 1\n",
    "    b = 8\n",
    "\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : s\n",
    "        },\n",
    "        \"quantization\" : {\n",
    "            \"type\" : q,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    lenet5_mcu_model.cpu()\n",
    "    compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape)\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    compressed_lenet5_mcu_model.cpu()\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f}\")\n",
    "\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-5,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    compressed_lenet5_mcu_model.fit(\n",
    "        mnist_train_loader, \n",
    "        15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        verbose = False,\n",
    "        device=DEVICE,\n",
    "        compression_config=compression_config,\n",
    "        callbacks = [early_stopper]\n",
    "    )\n",
    "    after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    print(f\"After training, sparsity = {i/RANGE:.2f}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "    with open(log_compression_details_file, \"a\") as file:\n",
    "        file.write(f\"{s}, {q}, {b}, {size}, {size/original_size*100:9.4f}, {before_acc:9.4f}, {after_acc:9.4f}, {original_acc-before_acc:9.4f}, {original_acc-after_acc:9.4f}\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5278080",
   "metadata": {},
   "outputs": [],
   "source": [
    " sparsity_per_layer = 0.1\n",
    "lenet5_model.to(\"cpu\")\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "# acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "# print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.to(DEVICE)\n",
    "lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=DEVICE,\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10372455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
