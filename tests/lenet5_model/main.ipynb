{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df77885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    AvgPool2d,\n",
    "    BatchNorm2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    ReLU6,\n",
    "    MaxPool2d,\n",
    "    Flatten, \n",
    "\n",
    "    EarlyStopper,\n",
    "    quantize_per_tensor_assy,\n",
    "    quantize_per_tensor_sy,\n",
    "    dequantize_per_tensor_assy,\n",
    "    dequantize_per_tensor_sy,\n",
    "    \n",
    "    QuantizationGranularity,\n",
    "    QuantizationScaleType,\n",
    "    QuantizationScheme\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bf3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = f\"lenet5_state_dict.pth\"\n",
    "log_compression_details_file = \"lenet5_compression_log.csv\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 28, 28)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize(input_shape[1:]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"../../../Datasets/\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"../../../Datasets/\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=tuple([2]*4), bias=False),\n",
    "    BatchNorm2d(num_features=6),\n",
    "    ReLU(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    BatchNorm2d(num_features=16),\n",
    "    ReLU(),\n",
    "    # ReLU6(),\n",
    "\n",
    "    # MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "    AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Linear(in_features=16*5*5, out_features=84, bias=False),\n",
    "    ReLU(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f8fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=5, pad=[2]*4, bias=True),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Conv2d(in_channels=6, out_channels=3, kernel_size=1, stride=1, pad=[0]*4, bias=False),\n",
    "#     MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*3*3, out_features=84, bias=False),\n",
    "#     ReLU(),\n",
    "#     Linear(in_features=84, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b811aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=5, pad=[2]*4, bias=True),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*6*6, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.cpu()\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True), strict=False)\n",
    "    lenet5_model.to(DEVICE)\n",
    "\n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"validation_loss\",\n",
    "        min_valid_diff=1e-7,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 25, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\" : accuracy_fun},\n",
    "        callbacks=[early_stopper],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    lenet5_model.cpu()\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    lenet5_model.to(DEVICE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.16\n",
      "The original model accuracy is 99.16% with size 148240 bytes.\n",
      "tensor([[-11.1386,  -5.0069,  -1.5617,  -2.5212,  -5.7953,  -7.7922, -11.7679,\n",
      "           5.8465,  -5.1975,  -2.0831]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9916, 148240)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(original_acc*100)\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n",
    "print(lenet5_mcu_model.test(device=DEVICE, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\"))\n",
    "original_acc, original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "602d750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 145.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9899"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model.fuse().to(DEVICE).evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ef5231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv2d_0): Conv2dReLU(\n",
       "    1, 6, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (maxpool2d_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_1): Conv2dReLU(\n",
       "    6, 16, kernel_size=(5, 5), stride=(1, 1)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (avgpool2d_0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (flatten_0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_0): LinearReLU(\n",
       "    in_features=400, out_features=84, bias=False\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (linear_1): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model.fuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4279cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11.1386,  -5.0069,  -1.5617,  -2.5212,  -5.7953,  -7.7922, -11.7679,\n",
       "           5.8465,  -5.1975,  -2.0831]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model.test(device=DEVICE, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2013bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compression_dict = lenet5_mcu_model.get_all_compression_hyperparameter()\n",
    "# print(len(compression_dict))\n",
    "# print((compression_dict)[0])\n",
    "# lenet5_mcu_model.decode_compression_dict_hyperparameter(compression_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea6bb211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x740e9e9e3710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e407525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 71.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 8 acc = 97.3300 size =   16.7175   83.2825\n",
      "tensor([[-8.6272, -1.0004, -1.6130, -2.6076, -3.1796, -6.5152, -9.0342,  4.2197,\n",
      "         -4.2886, -2.0837]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sp = .2\n",
    "s = QuantizationScheme.DYNAMIC\n",
    "g = QuantizationGranularity.PER_TENSOR\n",
    "b = 8\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : sp,\n",
    "        \"metric\" : \"l2\"\n",
    "    },\n",
    "    \"quantize\" : {\n",
    "        \"scheme\" : s,\n",
    "        \"granularity\": g,\n",
    "        \"bitwidth\" : b\n",
    "    }\n",
    "}\n",
    "\n",
    "compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"Before training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "\n",
    "print(compressed_lenet5_mcu_model.test(device=DEVICE, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13de812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.6272, -1.0004, -1.6130, -2.6076, -3.1796, -6.5152, -9.0342,  4.2197,\n",
       "         -4.2886, -2.0837]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model.eval()\n",
    "compressed_lenet5_mcu_model.test(device=DEVICE, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3bc20ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'input_quantize'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m test_input = compressed_lenet5_mcu_model.test_input[\u001b[32m0\u001b[39m].unsqueeze(dim=\u001b[32m0\u001b[39m).clone()\n\u001b[32m      3\u001b[39m conv0 = compressed_lenet5_mcu_model[\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m test_input_quant = \u001b[43mconv0\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput_quantize\u001b[49m.apply(test_input)\n\u001b[32m      5\u001b[39m test_input_quant = nn.functional.pad(test_input_quant, [\u001b[32m2\u001b[39m]*\u001b[32m4\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m\"\u001b[39m, conv0.input_quantize.zero_point.item())\n\u001b[32m      6\u001b[39m weight_quant = conv0.weight_quantize.apply(conv0.weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Conv2d' object has no attribute 'input_quantize'"
     ]
    }
   ],
   "source": [
    "test_input = compressed_lenet5_mcu_model.test_input[0].unsqueeze(dim=0).clone()\n",
    "\n",
    "conv0 = compressed_lenet5_mcu_model[0]\n",
    "test_input_quant = conv0.input_quantize.apply(test_input)\n",
    "test_input_quant = nn.functional.pad(test_input_quant, [2]*4, \"constant\", conv0.input_quantize.zero_point.item())\n",
    "weight_quant = conv0.weight_quantize.apply(conv0.weight)\n",
    "bias_quant = conv0.bias_quantize.apply(conv0.bias)\n",
    "\n",
    "output_quant = nn.functional.conv2d(\n",
    "    test_input_quant.to(torch.int32) - conv0.input_quantize.zero_point.to(torch.int32), weight_quant.to(torch.int32), bias_quant, stride=conv0.stride)\n",
    "\n",
    "# test_input = conv0(test_input)\n",
    "\n",
    "# relu0 = compressed_lenet5_mcu_model[1]\n",
    "# test_input = relu0(test_input)\n",
    "\n",
    "# linear0 = compressed_lenet5_mcu_model[2]\n",
    "# test_input = linear0(test_input)\n",
    "\n",
    "test_input, test_input.shape\n",
    "# output_quant, output_quant.shape, ((torch.round(output_quant*conv0.input_quantize.scale*conv0.weight_quantize.scale / conv0.output_quantize.scale) + conv0.output_quantize.zero_point) - conv0.output_quantize.zero_point) * conv0.output_quantize.scale \n",
    "output_quant, output_quant.shape, ((torch.round(output_quant*conv0.input_quantize.scale*conv0.weight_quantize.scale / conv0.output_quantize.scale) + conv0.output_quantize.zero_point))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4535e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -8450,  37600,   6009,  24471, -64189,  15056, -92124,  37367, -13474,\n",
       "          -25057]], dtype=torch.int32),\n",
       " torch.Size([1, 10]),\n",
       " tensor([[  -2.,   56.,   17.,   40.,  -72.,   28., -107.,   56.,   -8.,  -23.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = compressed_lenet5_mcu_model.test_input[0].unsqueeze(dim=0).clone()\n",
    "\n",
    "conv0 = compressed_lenet5_mcu_model[0]\n",
    "test_input = conv0(test_input)\n",
    "\n",
    "relu0 = compressed_lenet5_mcu_model[1]\n",
    "test_input = relu0(test_input)\n",
    "\n",
    "flatten0 = compressed_lenet5_mcu_model[2]\n",
    "test_input = flatten0(test_input)\n",
    "\n",
    "linear0 = compressed_lenet5_mcu_model[3]\n",
    "# test_input = linear0(test_input)\n",
    "\n",
    "test_input_quant = linear0.input_quantize.apply(test_input)\n",
    "weight_quant = linear0.weight_quantize.apply(linear0.weight)\n",
    "bias_quant = linear0.bias_quantize.apply(linear0.bias)\n",
    "\n",
    "output_quant = nn.functional.linear(\n",
    "    test_input_quant.to(torch.int32) - linear0.input_quantize.zero_point.to(torch.int32), weight_quant.to(torch.int32), bias_quant)\n",
    "\n",
    "# last_layer = linear0\n",
    "# print(test_input / last_layer.output_quantize.scale + last_layer.output_quantize.zero_point)\n",
    "\n",
    "\n",
    "test_input, test_input.shape\n",
    "output_quant, output_quant.shape, ((torch.round(output_quant*linear0.input_quantize.scale*linear0.weight_quantize.scale / linear0.output_quantize.scale) + linear0.output_quantize.zero_point))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117ce920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.7270e-06), tensor(0.0014), tensor(9, dtype=torch.int8))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear0.input_quantize.scale * linear0.weight_quantize.scale, linear0.output_quantize.scale, linear0.output_quantize.zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe019b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-128, dtype=torch.int8),\n",
       " tensor(-30, dtype=torch.int8),\n",
       " tensor(-30, dtype=torch.int8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear0.input_quantize.zero_point, conv0.output_quantize.zero_point, relu0.input_quantize.zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ef04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee66837",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3730829179.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msp = .5\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " sp = .5\n",
    "# s = QuantizationScheme.DYNAMIC\n",
    "g = QuantizationGranularity.PER_TENSOR\n",
    "b = 2\n",
    "for s in [QuantizationScheme.DYNAMIC, QuantizationScheme.STATIC]:\n",
    "    print(s)\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : sp,\n",
    "            \"metric\" : \"l2\"\n",
    "        },\n",
    "        # \"quantize\" : {\n",
    "        #     \"scheme\" : s,\n",
    "        #     \"granularity\": g,\n",
    "        #     \"bitwidth\" : b\n",
    "        # }\n",
    "    }\n",
    "\n",
    "    compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    size = 0\n",
    "    print(f\"Before training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "\n",
    "    print(\"#\"*40, \"Training\", \"#\"*40)\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"validation_acc\",\n",
    "        min_valid_diff=.001,\n",
    "        mode=\"max\",\n",
    "        patience=3,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    # optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    compressed_lenet5_mcu_model.fit(\n",
    "        mnist_train_loader, \n",
    "        15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        verbose = True,\n",
    "        device=DEVICE,\n",
    "        callbacks = [early_stopper]\n",
    "    )\n",
    "\n",
    "\n",
    "    after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    print(f\"After training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "print(compressed_lenet5_mcu_model.test(device=DEVICE, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3978d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sp = .9\n",
    "# s = QuantizationScheme.DYNAMIC\n",
    "s = QuantizationScheme.STATIC\n",
    "g = QuantizationGranularity.PER_TENSOR\n",
    "# g = QuantizationGranularity.PER_CHANNEL\n",
    "b = 8\n",
    "\n",
    "# for i in range(0, 11):\n",
    "#     sp = i/10\n",
    "\n",
    "# for i in [8, 4, 2]:\n",
    "\n",
    "#     b = i\n",
    "\n",
    "RANGE = 10\n",
    "for i in range(100):\n",
    "    sp = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    s = random.choice([QuantizationScheme.NONE, QuantizationScheme.DYNAMIC, QuantizationScheme.STATIC])\n",
    "    g = random.choice([None, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_CHANNEL])\n",
    "    b = random.choice([None, 2, 4, 8])\n",
    "\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : sp,\n",
    "            \"metric\" : \"l2\"\n",
    "        },\n",
    "        \"quantize\" : {\n",
    "            \"scheme\" : s,\n",
    "            \"granularity\": g,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(sp, s, g, b)\n",
    "\n",
    "        # compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    # lenet5_mcu_model.cpu()\n",
    "    try:\n",
    "        compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    except ValueError:\n",
    "        continue\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "    try:\n",
    "        print(f\"Before training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "    except AttributeError:\n",
    "        print(f\"Before training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "        \n",
    "    # # compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "    # compressed_lenet5_mcu_model.to(DEVICE)\n",
    "    # # print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "    # print(\"#\"*40, \"Training\", \"#\"*40)\n",
    "    # early_stopper = EarlyStopper(\n",
    "    #     metric_name=\"validation_acc\",\n",
    "    #     min_valid_diff=.001,\n",
    "    #     mode=\"min\",\n",
    "    #     patience=3,\n",
    "    #     restore_best_state_dict=True,\n",
    "    # )\n",
    "\n",
    "    # criterion_fun = nn.CrossEntropyLoss()\n",
    "    # # optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    # compressed_lenet5_mcu_model.fit(\n",
    "    #     mnist_train_loader, \n",
    "    #     15, \n",
    "    #     criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    #     validation_dataloader=mnist_test_loader, \n",
    "    #     metrics={\"acc\": accuracy_fun},\n",
    "    #     verbose = True,\n",
    "    #     device=DEVICE,\n",
    "    #     callbacks = [early_stopper]\n",
    "    # # )\n",
    "    # after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    # try:\n",
    "    #     print(f\"After training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "    #     print(f\"compressed_lenet5_mcu_model_{sp}_{s.name}_{g.name}_{b}\")\n",
    "    # except AttributeError:\n",
    "    #     print(f\"After training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "    #     print(f\"compressed_lenet5_mcu_model_{sp}_{s}_{g}_{b}\")\n",
    "    # compressed_lenet5_mcu_model.cpu()\n",
    "    # torch.save(compressed_lenet5_mcu_model, f\"compressed_lenet5_mcu_model_{sp}_{s}_{q}_{b}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_scale * weight_scale).view(1, -1, 1, 1)\n",
    "input_scale * weight_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d73749",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.5\n",
    "q = 3\n",
    "b = 8\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    # \"quantization\" : {\n",
    "    #     \"type\" : q,\n",
    "    #     \"bitwidth\" : b\n",
    "    # }\n",
    "\n",
    "}\n",
    "\n",
    "lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "s = 0.5\n",
    "q = 3\n",
    "b = 4\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    \"quantization\" : {\n",
    "        \"type\" : q,\n",
    "        \"bitwidth\" : b\n",
    "    }\n",
    "}\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = compressed_lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e02d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2343fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_lenet5_mcu_model.test(device=DEVICE), \\\n",
    "quantize_per_tensor_assy(\n",
    "    compressed_lenet5_mcu_model.test(device=DEVICE),\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c44390",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_lenet5_mcu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c49992",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_lenet5_mcu_model.cpu()\n",
    "test_input = compressed_lenet5_mcu_model.test_input.clone()\n",
    "\n",
    "test_input_quant = quantize_per_tensor_assy(\n",
    "    test_input,\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"],\n",
    ")\n",
    "\n",
    "test_input_real = dequantize_per_tensor_assy(\n",
    "    test_input_quant, \n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    ")\n",
    "\n",
    "i = 0\n",
    "# print(\"original real\", test_input[0,0,i])\n",
    "# print(\"quant real\", test_input_real[0,0,i])\n",
    "# print(\"quant\", test_input_quant[0,0,i])\n",
    "# line = torch.clamp(test_input[0,0,i]/compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"] + \\\n",
    "#                    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], -128, 127)\n",
    "# print(line)\n",
    "# print((line- compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]) * compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"])\n",
    "\n",
    "\n",
    "conv0 = compressed_lenet5_mcu_model[0]\n",
    "test_input_real = conv0(test_input_real)\n",
    "\n",
    "relu0 = compressed_lenet5_mcu_model[1]\n",
    "test_input_real = relu0(test_input_real)\n",
    "i = 5*2\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i:i+2])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i:i+2]\n",
    ")\n",
    "avgpool_0 = compressed_lenet5_mcu_model[2]\n",
    "test_input_real = avgpool_0(test_input_real)\n",
    "\n",
    "# flatten0 = compressed_lenet5_mcu_model[2]\n",
    "# test_input_real = flatten0(test_input_real)\n",
    "\n",
    "# linear0 = compressed_lenet5_mcu_model[3]\n",
    "# test_input_real = linear0(test_input_real)\n",
    "\n",
    "next_layer = compressed_lenet5_mcu_model[0]\n",
    "\n",
    "i = 5\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i]\n",
    ")\n",
    "\n",
    "# pad_input = nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     )\n",
    "# pad_weight = quant_weight.to(torch.int32)\n",
    "\n",
    "# quant_weight = quantize_per_tensor_sy(\n",
    "#         conv0.weight, \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#     )\n",
    "# test_input_quant = nn.functional.conv2d(\n",
    "#     nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     ),\n",
    "#     quant_weight.to(torch.int32),\n",
    "#     stride=5,\n",
    "# )\n",
    "\n",
    "# print(test_input_quant)\n",
    "# print(test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"])\n",
    "\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(test_input_real)\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_real,\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     nn.functional.conv2d(\n",
    "#         test_input_real, \n",
    "#         dequantize_per_tensor_sy(\n",
    "#             quant_weight,\n",
    "#                 conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#             ),\n",
    "#         stride=5\n",
    "#         # quantize_per_tensor_sy(\n",
    "#         #     conv0.weight, \n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#         # ).to(torch.int32),\n",
    "#         # stride=5,\n",
    "#     )\n",
    "\n",
    "# )\n",
    "# next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    " sparsity_per_layer = 0.25\n",
    "RANGE = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(log_compression_details_file):\n",
    "    with open(log_compression_details_file, \"w\") as file:\n",
    "        file.write(f\"sparsity, quantization_type, bitwidth, size, size_ratio, before acc, after acc, before acc_drop, after acc_drop\\n\")\n",
    "        # file.write(f\"sparsity, quantizaion_type, bitwidth, before acc, after acc\\n\")\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    # s = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    # q = random.choice([QUANTIZATION_NONE, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR])\n",
    "    # b = random.choice([4, 8])\n",
    "    # print(f\"sample number {i} ->  sparsity = {s}, q_type = {q}, bitwidth = {b}\")\n",
    "\n",
    "    s = 0.\n",
    "    q = 1\n",
    "    b = 8\n",
    "\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : s\n",
    "        },\n",
    "        \"quantization\" : {\n",
    "            \"type\" : q,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    lenet5_mcu_model.cpu()\n",
    "    compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape)\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    compressed_lenet5_mcu_model.cpu()\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f}\")\n",
    "\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-5,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    compressed_lenet5_mcu_model.fit(\n",
    "        mnist_train_loader, \n",
    "        15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        verbose = False,\n",
    "        device=DEVICE,\n",
    "        compression_config=compression_config,\n",
    "        callbacks = [early_stopper]\n",
    "    )\n",
    "    after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    print(f\"After training, sparsity = {i/RANGE:.2f}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "    with open(log_compression_details_file, \"a\") as file:\n",
    "        file.write(f\"{s}, {q}, {b}, {size}, {size/original_size*100:9.4f}, {before_acc:9.4f}, {after_acc:9.4f}, {original_acc-before_acc:9.4f}, {original_acc-after_acc:9.4f}\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5278080",
   "metadata": {},
   "outputs": [],
   "source": [
    " sparsity_per_layer = 0.1\n",
    "lenet5_model.to(\"cpu\")\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "# acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "# print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.to(DEVICE)\n",
    "lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=DEVICE,\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10372455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
