{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4441fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df77885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    MaxPool2d,\n",
    "    Flatten\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = f\"lenet5_state_dict_{DEVICE}.pth\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e4fe7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"./datasets\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"./datasets\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True)\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Linear(in_features=16*5*5, out_features=84, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True))\n",
    "    \n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    \n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        device=DEVICE\n",
    "    )\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ae4482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.75it/s]\n"
     ]
    }
   ],
   "source": [
    "original_acc = lenet5_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n",
    "# original_size = lenet5_model.get_size_in_bits()//8\n",
    "# print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 47.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original model accuracy is 99.11% with size 148424 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lenet5_model.cpu()\n",
    "\n",
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5278080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.1 accuracy is 95.12%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:05<15:17, 65.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0049 | validation loss 0.0035 | train acc 0.9543 | validation acc 0.9692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:12<14:21, 66.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0044 | validation loss 0.0035 | train acc 0.9607 | validation acc 0.9685\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.1\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10372455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.2 accuracy is 94.65%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:13<17:10, 73.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0048 | validation loss 0.0034 | train acc 0.9542 | validation acc 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:28<16:08, 74.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0043 | validation loss 0.0035 | train acc 0.9609 | validation acc 0.9668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:43<14:56, 74.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0042 | validation loss 0.0033 | train acc 0.9625 | validation acc 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:57<13:40, 74.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0042 | validation loss 0.0035 | train acc 0.9629 | validation acc 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [06:13<12:27, 74.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0040 | validation loss 0.0034 | train acc 0.9650 | validation acc 0.9692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:25<11:05, 73.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0039 | validation loss 0.0032 | train acc 0.9666 | validation acc 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:36<09:43, 72.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0037 | validation loss 0.0046 | train acc 0.9684 | validation acc 0.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:47<08:27, 72.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0038 | validation loss 0.0040 | train acc 0.9681 | validation acc 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [11:02<07:19, 73.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0037 | validation loss 0.0043 | train acc 0.9688 | validation acc 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [12:15<06:05, 73.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0022 | validation loss 0.0018 | train acc 0.9809 | validation acc 0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [13:26<04:49, 72.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0019 | validation loss 0.0019 | train acc 0.9833 | validation acc 0.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [14:38<03:36, 72.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0017 | validation loss 0.0018 | train acc 0.9848 | validation acc 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [15:54<02:26, 73.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0016 | validation loss 0.0016 | train acc 0.9851 | validation acc 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [17:08<01:13, 73.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0015 | validation loss 0.0016 | train acc 0.9857 | validation acc 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [18:22<00:00, 73.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0015 | validation loss 0.0016 | train acc 0.9859 | validation acc 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.2 accuracy is 98.57%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.3 accuracy is 83.71%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:13<17:10, 73.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0050 | validation loss 0.0041 | train acc 0.9537 | validation acc 0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:24<15:36, 72.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0044 | validation loss 0.0039 | train acc 0.9590 | validation acc 0.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:37<14:27, 72.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0044 | validation loss 0.0034 | train acc 0.9602 | validation acc 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:50<13:19, 72.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0042 | validation loss 0.0041 | train acc 0.9629 | validation acc 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [06:03<12:08, 72.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0042 | validation loss 0.0035 | train acc 0.9634 | validation acc 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:16<10:56, 72.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0041 | validation loss 0.0037 | train acc 0.9645 | validation acc 0.9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:28<09:39, 72.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0025 | validation loss 0.0021 | train acc 0.9777 | validation acc 0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:38<08:23, 71.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0019 | validation loss 0.0018 | train acc 0.9823 | validation acc 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:50<07:10, 71.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0018 | validation loss 0.0017 | train acc 0.9825 | validation acc 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [12:03<06:01, 72.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0017 | validation loss 0.0017 | train acc 0.9839 | validation acc 0.9835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [13:15<04:48, 72.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0016 | validation loss 0.0016 | train acc 0.9849 | validation acc 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [14:27<03:36, 72.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0015 | validation loss 0.0015 | train acc 0.9858 | validation acc 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [15:39<02:24, 72.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0015 | validation loss 0.0016 | train acc 0.9856 | validation acc 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [16:52<01:12, 72.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0014 | validation loss 0.0016 | train acc 0.9870 | validation acc 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [18:05<00:00, 72.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0014 | validation loss 0.0015 | train acc 0.9861 | validation acc 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.3 accuracy is 98.42%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.4 accuracy is 74.37%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:13<17:09, 73.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0049 | validation loss 0.0030 | train acc 0.9531 | validation acc 0.9703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:25<15:46, 72.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0046 | validation loss 0.0036 | train acc 0.9591 | validation acc 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:38<14:32, 72.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0044 | validation loss 0.0040 | train acc 0.9599 | validation acc 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:48<13:10, 71.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0043 | validation loss 0.0031 | train acc 0.9616 | validation acc 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [06:03<12:07, 72.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0023 | validation loss 0.0020 | train acc 0.9777 | validation acc 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:17<10:59, 73.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0019 | validation loss 0.0018 | train acc 0.9820 | validation acc 0.9822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:30<09:46, 73.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0018 | validation loss 0.0017 | train acc 0.9834 | validation acc 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:45<08:34, 73.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0016 | validation loss 0.0016 | train acc 0.9844 | validation acc 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:59<07:23, 73.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0016 | validation loss 0.0015 | train acc 0.9851 | validation acc 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [12:14<06:10, 74.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0015 | validation loss 0.0015 | train acc 0.9855 | validation acc 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [13:27<04:55, 73.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0015 | validation loss 0.0015 | train acc 0.9858 | validation acc 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [14:39<03:39, 73.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0014 | validation loss 0.0016 | train acc 0.9855 | validation acc 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [15:53<02:27, 73.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0013 | validation loss 0.0013 | train acc 0.9871 | validation acc 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [17:06<01:13, 73.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0013 | validation loss 0.0015 | train acc 0.9874 | validation acc 0.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [18:18<00:00, 73.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0013 | validation loss 0.0016 | train acc 0.9868 | validation acc 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 39.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.4 accuracy is 98.47%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.5 accuracy is 48.18%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:12<16:59, 72.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0062 | validation loss 0.0051 | train acc 0.9398 | validation acc 0.9497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:27<15:57, 73.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0051 | validation loss 0.0044 | train acc 0.9513 | validation acc 0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:42<14:55, 74.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0046 | validation loss 0.0046 | train acc 0.9561 | validation acc 0.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:55<13:34, 74.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0047 | validation loss 0.0035 | train acc 0.9571 | validation acc 0.9668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [06:07<12:12, 73.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0044 | validation loss 0.0041 | train acc 0.9593 | validation acc 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:18<10:50, 72.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0044 | validation loss 0.0049 | train acc 0.9593 | validation acc 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:27<09:29, 71.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0044 | validation loss 0.0037 | train acc 0.9601 | validation acc 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:35<08:11, 70.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0027 | validation loss 0.0025 | train acc 0.9746 | validation acc 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:43<06:58, 69.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0023 | validation loss 0.0023 | train acc 0.9786 | validation acc 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [11:54<05:50, 70.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0021 | validation loss 0.0021 | train acc 0.9797 | validation acc 0.9804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [13:05<04:40, 70.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0020 | validation loss 0.0020 | train acc 0.9806 | validation acc 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [14:16<03:31, 70.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0019 | validation loss 0.0019 | train acc 0.9817 | validation acc 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [15:25<02:19, 69.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0019 | validation loss 0.0018 | train acc 0.9818 | validation acc 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [16:32<01:09, 69.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0017 | validation loss 0.0020 | train acc 0.9832 | validation acc 0.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [17:40<00:00, 70.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0018 | validation loss 0.0018 | train acc 0.9831 | validation acc 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.5 accuracy is 98.21%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.6 accuracy is 33.56%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:10<16:32, 70.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0068 | validation loss 0.0056 | train acc 0.9326 | validation acc 0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:19<15:05, 69.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0052 | validation loss 0.0061 | train acc 0.9502 | validation acc 0.9404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:27<13:45, 68.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0049 | validation loss 0.0047 | train acc 0.9525 | validation acc 0.9564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:35<12:35, 68.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0047 | validation loss 0.0044 | train acc 0.9560 | validation acc 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [05:45<11:30, 69.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0046 | validation loss 0.0063 | train acc 0.9565 | validation acc 0.9412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [06:53<10:18, 68.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0048 | validation loss 0.0041 | train acc 0.9561 | validation acc 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:03<09:11, 69.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0045 | validation loss 0.0066 | train acc 0.9580 | validation acc 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:13<08:04, 69.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0046 | validation loss 0.0039 | train acc 0.9583 | validation acc 0.9640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:22<06:56, 69.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0045 | validation loss 0.0049 | train acc 0.9577 | validation acc 0.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [11:29<05:43, 68.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0045 | validation loss 0.0041 | train acc 0.9587 | validation acc 0.9638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [12:40<04:36, 69.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0043 | validation loss 0.0043 | train acc 0.9608 | validation acc 0.9632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [13:48<03:26, 68.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0030 | validation loss 0.0024 | train acc 0.9720 | validation acc 0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [14:57<02:18, 69.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0026 | validation loss 0.0024 | train acc 0.9750 | validation acc 0.9768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [16:04<01:08, 68.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0024 | validation loss 0.0024 | train acc 0.9772 | validation acc 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [17:12<00:00, 68.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0023 | validation loss 0.0022 | train acc 0.9788 | validation acc 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.6 accuracy is 97.82%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.7 accuracy is 11.02%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:10<16:30, 70.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0094 | validation loss 0.0059 | train acc 0.9058 | validation acc 0.9392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:21<15:21, 70.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0063 | validation loss 0.0051 | train acc 0.9372 | validation acc 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:34<14:21, 71.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0058 | validation loss 0.0053 | train acc 0.9436 | validation acc 0.9517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:45<13:03, 71.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0056 | validation loss 0.0052 | train acc 0.9462 | validation acc 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [05:55<11:47, 70.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0054 | validation loss 0.0049 | train acc 0.9485 | validation acc 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:08<10:45, 71.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0053 | validation loss 0.0055 | train acc 0.9487 | validation acc 0.9461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:18<09:28, 71.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0053 | validation loss 0.0046 | train acc 0.9486 | validation acc 0.9557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:29<08:17, 71.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0050 | validation loss 0.0040 | train acc 0.9510 | validation acc 0.9613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [10:38<07:02, 70.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0050 | validation loss 0.0049 | train acc 0.9515 | validation acc 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [11:45<05:47, 69.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0048 | validation loss 0.0044 | train acc 0.9537 | validation acc 0.9563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [12:54<04:37, 69.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0049 | validation loss 0.0043 | train acc 0.9535 | validation acc 0.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [14:03<03:27, 69.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0036 | validation loss 0.0033 | train acc 0.9644 | validation acc 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [15:14<02:19, 69.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0032 | validation loss 0.0031 | train acc 0.9686 | validation acc 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [16:23<01:09, 69.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0031 | validation loss 0.0028 | train acc 0.9704 | validation acc 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [17:34<00:00, 70.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0030 | validation loss 0.0026 | train acc 0.9712 | validation acc 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.7 accuracy is 97.26%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.8 accuracy is 13.45%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [01:14<17:22, 74.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0113 | validation loss 0.0076 | train acc 0.8859 | validation acc 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [02:26<15:50, 73.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0080 | validation loss 0.0068 | train acc 0.9196 | validation acc 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [03:37<14:26, 72.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0074 | validation loss 0.0062 | train acc 0.9272 | validation acc 0.9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [04:47<13:04, 71.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0068 | validation loss 0.0057 | train acc 0.9332 | validation acc 0.9440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [05:57<11:46, 70.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0068 | validation loss 0.0066 | train acc 0.9339 | validation acc 0.9350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [07:07<10:36, 70.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0067 | validation loss 0.0065 | train acc 0.9348 | validation acc 0.9371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [08:17<09:23, 70.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0064 | validation loss 0.0053 | train acc 0.9370 | validation acc 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:29<08:15, 70.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0065 | validation loss 0.0056 | train acc 0.9367 | validation acc 0.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [09:54<08:40, 74.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=\u001b[32m1.e-2\u001b[39m)\n\u001b[32m     10\u001b[39m lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mlenet5_mcu_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# mnist_test_loader,\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmnist_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizion_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmnist_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43macc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fun\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression_aware\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m lenet5_model = lenet5_model.prune_channel(sparsity_per_layer)\n\u001b[32m     23\u001b[39m acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/models/sequential.py:158\u001b[39m, in \u001b[36mSequential.fit\u001b[39m\u001b[34m(self, train_dataloader, epochs, criterion_fun, optimizer_fun, lr_scheduler, validation_dataloader, metrics, compression_aware, device)\u001b[39m\n\u001b[32m    155\u001b[39m y_true = y_true.to(device)\n\u001b[32m    157\u001b[39m optimizer_fun.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m loss = criterion_fun(y_pred, y_true)\n\u001b[32m    160\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/models/sequential.py:113\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# if hasattr(self, \"quantization_type\") and (getattr(self, \"quantization_type\") == STATIC_QUANTIZATION_PER_TENSOR\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m#                                            or getattr(self, \"quantization_type\") == STATIC_QUANTIZATION_PER_CHANNEL):\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m#     if not hasattr(self, \"test_input_quant\"):\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m \n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Pass through all layers\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/layers/conv.py:65\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Use pruned or quantized weights if available\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# weight = self.weight_dmc if hasattr(self, \"weight_dmc\") else self.weight\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# bias = self.bias_dmc if hasattr(self, \"bias_dmc\") else self.bias\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpruned\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_prune_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# print(\"conv prunned\")\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# # Handle different quantization modes\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m \n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Perform convolution with appropriate padding\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28msuper\u001b[39m().forward(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/layers/conv.py:237\u001b[39m, in \u001b[36mapply_prune_channel\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m     keep_current_channel_index = torch.nonzero(\n\u001b[32m    225\u001b[39m         (channel_importance >= threshold).to(torch.int32)\n\u001b[32m    226\u001b[39m     ).squeeze(dim=1)\n\u001b[32m    227\u001b[39m     setattr(self, \"keep_current_channel_index\", keep_current_channel_index)\n\u001b[32m    229\u001b[39m     # # Update weights and biases\n\u001b[32m    230\u001b[39m     # self.register_buffer(\n\u001b[32m    231\u001b[39m     #     \"weight_dmc\", \n\u001b[32m    232\u001b[39m     #     torch.index_select(weight_dmc, 0, keep_current_channel_index)\n\u001b[32m    233\u001b[39m     # )\n\u001b[32m    234\u001b[39m     # weight_mask[keep_current_channel_index] = 1\n\u001b[32m    235\u001b[39m     # setattr(self, \"weight_mask\", weight_mask)\n\u001b[32m    236\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     # self.register_buffer(\n\u001b[32m    238\u001b[39m     #     \"bias_dmc\", \n\u001b[32m    239\u001b[39m     #     torch.index_select(bias, 0, keep_current_channel_index)\n\u001b[32m    240\u001b[39m     # )\n\u001b[32m    241\u001b[39m     # bias_mask[keep_current_channel_index] = 1\n\u001b[32m    242\u001b[39m     # setattr(self, \"bias_mask\", bias_mask)\n\u001b[32m    243\u001b[39m self.set_prune_parameters()\n\u001b[32m    245\u001b[39m return keep_current_channel_index\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.9 accuracy is 9.22%.\n",
      "The accurancy drop is 89.89% and size drop is 0.00%.\n",
      "tensor([[-0.0105, -0.0856, -0.0056, -0.1240,  0.0680, -0.1196, -0.1996,  0.1272,\n",
      "          0.3142, -0.0742]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 8 accuracy is 99.18%.\n",
      "The accurancy drop is -0.07% and size drop is 74.75%.\n",
      "tensor([[ 11.1611,  -7.6662,  -1.7230,  -9.1078, -10.8982,  -5.0437,  -9.2423,\n",
      "          -5.6716,  -1.8833,  -7.8008]])\n"
     ]
    }
   ],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 44.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 4 accuracy is 99.16%.\n",
      "The accurancy drop is -0.05% and size drop is 87.37%.\n",
      "tensor([[ 11.1611,  -7.6662,  -1.7230,  -9.1078, -10.8982,  -5.0437,  -9.2423,\n",
      "          -5.6716,  -1.8833,  -7.8008]])\n"
     ]
    }
   ],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 8 accuracy is 99.04%.\n",
      "The accurancy drop is 0.07% and size drop is 74.45%.\n",
      "tensor([[ 11.1611,  -7.6662,  -1.7230,  -9.1078, -10.8982,  -5.0437,  -9.2423,\n",
      "          -5.6716,  -1.8833,  -7.8008]])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'layer_def' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe accurancy drop is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(original_acc\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39macc)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% and size drop is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(original_size\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39msize)/original_size*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(lenet5_mcu_model.test())\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mlenet5_mcu_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlenet5_mcu_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Arduino Nano 33 BLE/src/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Arduino Nano 33 BLE/include/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m lenet5_mcu_model.convert_to_c(var_name=\u001b[33m\"\u001b[39m\u001b[33mlenet5_mcu_model\u001b[39m\u001b[33m\"\u001b[39m, src_dir=\u001b[33m\"\u001b[39m\u001b[33m./HP HP Pavilion Laptop 15-cs3xxx/src/\u001b[39m\u001b[33m\"\u001b[39m, include_dir=\u001b[33m\"\u001b[39m\u001b[33m./HP HP Pavilion Laptop 15-cs3xxx/include/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/models/sequential.py:712\u001b[39m, in \u001b[36mSequential.convert_to_c\u001b[39m\u001b[34m(self, var_name, src_dir, include_dir)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[33m\"\u001b[39m\u001b[33mconvert_to_c\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    711\u001b[39m     layers_def += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    &\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     layer_header, layer_def, layer_param_def = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m     layers_header += layer_header\n\u001b[32m    714\u001b[39m     param_definition_file += layer_param_def\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/layers/conv.py:547\u001b[39m, in \u001b[36mConv2d.convert_to_c\u001b[39m\u001b[34m(self, var_name)\u001b[39m\n\u001b[32m    536\u001b[39m     layer_def = (\n\u001b[32m    537\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_channel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_row_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_col_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_channel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    542\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(int32_t*)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_bias, *(float*)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_bias_scale);\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m     )\n\u001b[32m    545\u001b[39m layer_header += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mextern \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m layer_header, \u001b[43mlayer_def\u001b[49m, layer_param_def\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'layer_def' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
