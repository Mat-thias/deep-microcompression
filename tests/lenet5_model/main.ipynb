{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df77885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/Research/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    AvgPool2d,\n",
    "    BatchNorm2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    ReLU6,\n",
    "    MaxPool2d,\n",
    "    Flatten, \n",
    "\n",
    "    EarlyStopper,\n",
    "    quantize_per_tensor_assy,\n",
    "    quantize_per_tensor_sy,\n",
    "    dequantize_per_tensor_assy,\n",
    "    dequantize_per_tensor_sy,\n",
    "    \n",
    "    QuantizationGranularity,\n",
    "    QuantizationScaleType,\n",
    "    QuantizationScheme\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bf3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = f\"lenet5_state_dict_{DEVICE}.pth\"\n",
    "log_compression_details_file = \"lenet5_compression_log.csv\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45406f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../../../Datasets/MNIST/MNIST/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls ../../../Datasets/MNIST/MNIST/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 28, 28)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize(input_shape[1:]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"../../../Datasets/\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"../../../Datasets/\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32, shuffle=False, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=tuple([2]*4), bias=False),\n",
    "    # BatchNorm2d(num_features=6),\n",
    "    ReLU6(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    # BatchNorm2d(num_features=16),\n",
    "    ReLU(),\n",
    "    # ReLU6(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "    # AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Linear(in_features=16*5*5, out_features=84, bias=False),\n",
    "    ReLU6(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "d3f8fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=5, pad=[2]*4, bias=True),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Conv2d(in_channels=6, out_channels=3, kernel_size=1, stride=1, pad=[0]*4, bias=False),\n",
    "#     MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*3*3, out_features=84, bias=False),\n",
    "#     ReLU(),\n",
    "#     Linear(in_features=84, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 2bdec34589c4228cd2e25b041b1e1cc5407bd964
   "execution_count": 7,
   "id": "b811aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=5, pad=[2]*4, bias=False),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*6*6, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:32<52:56, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 | train loss 0.0104 | validation loss 0.0037 | train acc 0.8948 | validation acc 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:59<47:36, 29.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train loss 0.0035 | validation loss 0.0027 | train acc 0.9648 | validation acc 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [01:28<47:33, 29.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    2 | train loss 0.0026 | validation loss 0.0026 | train acc 0.9735 | validation acc 0.9739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [01:58<47:12, 29.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    3 | train loss 0.0022 | validation loss 0.0016 | train acc 0.9781 | validation acc 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [02:26<46:05, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    4 | train loss 0.0019 | validation loss 0.0016 | train acc 0.9806 | validation acc 0.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [02:53<44:07, 28.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    5 | train loss 0.0017 | validation loss 0.0015 | train acc 0.9826 | validation acc 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [03:20<43:06, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    6 | train loss 0.0015 | validation loss 0.0013 | train acc 0.9849 | validation acc 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [03:46<42:00, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    7 | train loss 0.0015 | validation loss 0.0015 | train acc 0.9847 | validation acc 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [04:12<40:41, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    8 | train loss 0.0014 | validation loss 0.0012 | train acc 0.9859 | validation acc 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [04:37<39:31, 26.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    9 | train loss 0.0013 | validation loss 0.0012 | train acc 0.9872 | validation acc 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [05:03<38:51, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   10 | train loss 0.0012 | validation loss 0.0013 | train acc 0.9877 | validation acc 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [05:28<37:59, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   11 | train loss 0.0012 | validation loss 0.0013 | train acc 0.9879 | validation acc 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [05:53<37:06, 25.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   12 | train loss 0.0008 | validation loss 0.0009 | train acc 0.9919 | validation acc 0.9905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [06:18<36:24, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   13 | train loss 0.0007 | validation loss 0.0008 | train acc 0.9934 | validation acc 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [06:43<35:51, 25.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   14 | train loss 0.0007 | validation loss 0.0009 | train acc 0.9931 | validation acc 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [07:10<36:01, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   15 | train loss 0.0006 | validation loss 0.0008 | train acc 0.9932 | validation acc 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [07:34<34:45, 25.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   16 | train loss 0.0007 | validation loss 0.0009 | train acc 0.9933 | validation acc 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [07:57<33:47, 24.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   17 | train loss 0.0006 | validation loss 0.0008 | train acc 0.9938 | validation acc 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [08:22<33:11, 24.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   18 | train loss 0.0006 | validation loss 0.0009 | train acc 0.9939 | validation acc 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [08:45<32:16, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   19 | train loss 0.0006 | validation loss 0.0007 | train acc 0.9944 | validation acc 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [09:09<31:35, 24.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   20 | train loss 0.0006 | validation loss 0.0008 | train acc 0.9946 | validation acc 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [09:32<31:09, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   21 | train loss 0.0006 | validation loss 0.0008 | train acc 0.9941 | validation acc 0.9918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [09:56<35:14, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   22 | train loss 0.0006 | validation loss 0.0008 | train acc 0.9938 | validation acc 0.9928\n",
      "Stopping Training of Sequential with at 20 epoch with best train_loss = 0.0005869271132407144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True), strict=True)\n",
    "    \n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    print(e)\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-7,\n",
    "        mode=\"min\",\n",
    "        patience=2,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 2, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\" : accuracy_fun},\n",
    "        callbacks=[early_stopper],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 82.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.33\n",
      "The original model accuracy is 99.33% with size 148064 bytes.\n",
      "tensor([[-10.5499,  -3.5355,   9.8397,  -3.2319,  -9.1715, -12.8788,  -4.4893,\n",
      "           0.5832,  -4.2970,  -7.2553]])\n"
=======
      "100%|██████████| 313/313 [00:02<00:00, 105.30it/s]\n"
>>>>>>> 2bdec34589c4228cd2e25b041b1e1cc5407bd964
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(0.9933, 148064)"
=======
       "(99.22, 148088)"
>>>>>>> 2bdec34589c4228cd2e25b041b1e1cc5407bd964
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(original_acc*100)\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n",
    "print(lenet5_mcu_model.test(device=DEVICE))\n",
    "original_acc, original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc3f894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7ad091945820>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3978d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.7500 size =    0.4235   99.5765\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.2700 size =    6.4384   93.5616\n",
      "0.5 QuantizationScheme.STATIC None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.8400 size =   25.0135   74.9865\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 20.5200 size =    1.4413   98.5587\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.7800 size =   21.4130   78.5870\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 36.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 35.0400 size =    2.3470   97.6530\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:06<00:00, 48.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.6300 size =   16.5827   83.4173\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 26.6000 size =   25.0000   75.0000\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 62.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.1500 size =    0.0648   99.9352\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 27.2700 size =    4.6784   95.3216\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 97.5200 size =    8.2924   91.7076\n",
      "0.3 QuantizationScheme.STATIC None 4\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 65.8900 size =    9.7120   90.2880\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 66.7400 size =    9.7120   90.2880\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 52.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.3000 size =    0.2121   99.7879\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 95.0000 size =   13.4651   86.5349\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.DYNAMIC None None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 12.5800 size =    0.2121   99.7879\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 35.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.7200 size =    0.0473   99.9527\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 64.6200 size =    4.8695   95.1305\n",
      "0.7 QuantizationScheme.STATIC None 4\n",
      "0.0 QuantizationScheme.STATIC None 8\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 52.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.6300 size =    0.7206   99.2794\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 57.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.6100 size =   10.7001   89.2999\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    6.2642   93.7358\n",
      "0.2 QuantizationScheme.DYNAMIC None 8\n",
      "0.5 QuantizationScheme.STATIC None 8\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 18.4100 size =    0.7341   99.2659\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 10.6000 size =    0.0338   99.9662\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 18.0200 size =    3.3675   96.6325\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 37.8700 size =    3.2263   96.7737\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 25.2700 size =    1.2920   98.7080\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 32.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.7200 size =   21.4130   78.5870\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.3700 size =   16.5827   83.4173\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.4 QuantizationScheme.DYNAMIC None 8\n",
      "0.9 QuantizationScheme.STATIC None None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1081   99.8919\n",
      "0.2 QuantizationScheme.NONE None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 98.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.NONE, granularity = None, bitwidth = None acc = 97.5700 size =   66.3308   33.6692\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3675   96.6325\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.6500 size =   10.7001   89.2999\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 41.9500 size =    3.2128   96.7872\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.DYNAMIC None None\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 17.2900 size =    2.3335   97.6665\n",
      "0.8 QuantizationScheme.DYNAMIC None 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 66.5700 size =    4.8695   95.1305\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6477   99.3523\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 13.4300 size =    2.5833   97.4167\n",
      "0.9 QuantizationScheme.STATIC None 8\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.6202   98.3798\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 57.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.9700 size =    0.4235   99.5765\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:11<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 22.2400 size =    1.3055   98.6945\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 38.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 70.7500 size =    4.8560   95.1440\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.4000 size =    0.2121   99.7879\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 53.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 25.0800 size =    1.2920   98.7080\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 31.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 35.9400 size =    2.3470   97.6530\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 21.2600 size =    1.4548   98.5452\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 34.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 93.7300 size =    8.3059   91.6941\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 96.9400 size =   16.5962   83.4038\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 39.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.9100 size =   21.3995   78.6005\n",
      "0.6 QuantizationScheme.DYNAMIC None 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.8500 size =   21.4130   78.5870\n",
      "0.2 QuantizationScheme.STATIC None 2\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "1.0 QuantizationScheme.STATIC None 2\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.4 QuantizationScheme.DYNAMIC None 8\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 62.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 70.8600 size =    4.8560   95.1440\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 94.7200 size =   13.4651   86.5349\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 36.8600 size =    3.2263   96.7737\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    6.2507   93.7493\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 19.7900 size =    0.7341   99.2659\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 65.8500 size =    4.8695   95.1305\n",
      "0.7 QuantizationScheme.DYNAMIC None 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 8.0600 size =    4.6649   95.3351\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.3000 size =   25.0000   75.0000\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.2000 size =    0.2121   99.7879\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    2.4429   97.5571\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.0700 size =   25.0135   74.9865\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.6500 size =    6.4384   93.5616\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.1812   98.8188\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 87.5500 size =    6.7464   93.2536\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 44.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 51.7600 size =    8.2924   91.7076\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 QuantizationScheme.DYNAMIC None 8\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.DYNAMIC None 8\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 13.1700 size =    2.5833   97.4167\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.4600 size =   16.5827   83.4173\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.4600 size =   16.5827   83.4173\n",
      "0.0 QuantizationScheme.NONE None 4\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 20.5000 size =    0.2256   99.7744\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 10.6500 size =    0.0338   99.9662\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.0324   99.9676\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 24.6900 size =    1.2920   98.7080\n",
      "0.5 QuantizationScheme.DYNAMIC None 2\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.3500 size =   12.5000   87.5000\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    5.3511   94.6489\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.6 QuantizationScheme.DYNAMIC None 4\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1081   99.8919\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1610   95.8390\n",
      "0.5 QuantizationScheme.DYNAMIC None None\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.1800 size =    0.2256   99.7744\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 93.7700 size =    6.7329   93.2671\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 96.8200 size =   16.5962   83.4038\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 22.5300 size =   16.5827   83.4173\n",
      "0.1 QuantizationScheme.STATIC None 8\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6612   99.3388\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 42.1700 size =    3.2128   96.7872\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.8400 size =    0.4370   99.5630\n",
      "0.7 QuantizationScheme.NONE None 4\n",
      "0.5 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 96.3700 size =   12.5135   87.4865\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 92.5200 size =   13.4786   86.5214\n",
      "0.1 QuantizationScheme.DYNAMIC None 8\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    5.3511   94.6489\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    2.4429   97.5571\n",
      "0.6 QuantizationScheme.NONE None 4\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 2\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 38.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 9.8000 size =    0.3613   99.6387\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 9.4400 size =    0.4235   99.5765\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 63.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.2900 size =   25.0000   75.0000\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 60.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 70.4200 size =    4.8560   95.1440\n",
      "0.7 QuantizationScheme.STATIC None 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3810   96.6190\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 41.0400 size =    3.2128   96.7872\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.4900 size =    0.2121   99.7879\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 60.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.3800 size =   16.5827   83.4173\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 13.2500 size =    2.5833   97.4167\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 30.6900 size =    4.6649   95.3351\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 39.0800 size =    3.2263   96.7737\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL None\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.1700 size =    0.0783   99.9217\n",
      "0.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 25.2300 size =    4.8560   95.1440\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 52.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.1677   98.8323\n",
      "0.8 QuantizationScheme.STATIC None 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 71.1000 size =    4.8560   95.1440\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1216   99.8784\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 21.4900 size =    1.4548   98.5452\n",
      "1.0 QuantizationScheme.DYNAMIC None 8\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 98.5200 size =   12.5000   87.5000\n",
      "0.0 QuantizationScheme.DYNAMIC None None\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.DYNAMIC None 8\n",
      "0.5 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 5.9600 size =    0.0648   99.9352\n",
      "0.7 QuantizationScheme.DYNAMIC None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 60.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.0189   99.9811\n",
      "0.2 QuantizationScheme.DYNAMIC None 8\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.8300 size =    0.4235   99.5765\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC None None\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 95.1300 size =   13.4651   86.5349\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.1 QuantizationScheme.STATIC None 2\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 12.9700 size =    0.0648   99.9352\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.6300 size =   16.5827   83.4173\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 36.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 11.8300 size =    6.4249   93.5751\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 62.4800 size =    9.7255   90.2745\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.STATIC None 4\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 36.0000 size =    6.4384   93.5616\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 31.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.5700 size =    0.2256   99.7744\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:06<00:00, 44.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 9.1400 size =    0.4235   99.5765\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 98.7700 size =   21.4130   78.5870\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR None\n",
      "1.0 QuantizationScheme.DYNAMIC None 8\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    1.6067   98.3933\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 58.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 13.0800 size =    0.2121   99.7879\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 12.9700 size =    0.0648   99.9352\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1610   95.8390\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 53.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 39.2000 size =    6.4249   93.5751\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 38.8200 size =    3.2263   96.7737\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 66.1400 size =    4.8695   95.1305\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.2 QuantizationScheme.NONE None 8\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.1081   99.8919\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 30.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 14.9000 size =    0.4370   99.5630\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 55.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 97.1800 size =    8.2924   91.7076\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.2200 size =   25.0000   75.0000\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 35.5800 size =    3.2263   96.7737\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 9.8000 size =    0.0189   99.9811\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 20.3000 size =    0.2256   99.7744\n",
      "0.2 QuantizationScheme.STATIC None 8\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 38.2400 size =    3.2263   96.7737\n",
      "0.1 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.0100 size =   21.3995   78.6005\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 99.0400 size =   25.0135   74.9865\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 88.9800 size =    6.7464   93.2536\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "1.0 QuantizationScheme.STATIC None 4\n",
      "0.6 QuantizationScheme.STATIC None 4\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 30.9800 size =    4.6649   95.3351\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 37.1200 size =    3.2263   96.7737\n",
      "1.0 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 58.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1475   95.8525\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 87.8900 size =    6.7464   93.2536\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 QuantizationScheme.DYNAMIC None 8\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3810   96.6190\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 13.4300 size =    0.2121   99.7879\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 96.5400 size =   12.5135   87.4865\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 31.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 22.1500 size =    1.3055   98.6945\n",
      "0.1 QuantizationScheme.STATIC None 4\n",
      "0.5 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.9 QuantizationScheme.STATIC None 8\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 34.5200 size =    2.3470   97.6530\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 34.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1610   95.8390\n",
      "1.0 QuantizationScheme.STATIC None 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n",
      "0.8 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 18.7900 size =    0.7341   99.2659\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 65.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 21.3000 size =    0.7206   99.2794\n",
      "0.7 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6612   99.3388\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 37.9600 size =    3.2263   96.7737\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 56.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    4.1475   95.8525\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.8 QuantizationScheme.STATIC None 8\n",
      "0.8 QuantizationScheme.NONE None 2\n",
      "0.0 QuantizationScheme.DYNAMIC None None\n",
      "0.4 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.1 QuantizationScheme.DYNAMIC None 2\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 20.9600 size =    1.4413   98.5587\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 60.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 97.7300 size =   16.5827   83.4173\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 30.8900 size =    4.6649   95.3351\n",
      "0.4 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 24.8200 size =    4.8560   95.1440\n",
      "1.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.3613   99.6387\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 31.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.2700 size =    6.4384   93.5616\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 QuantizationScheme.DYNAMIC None 4\n",
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 8 acc = 22.5300 size =   16.5827   83.4173\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 32.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 35.9700 size =    6.4384   93.5616\n",
      "0.8 QuantizationScheme.STATIC None 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 4\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 24.6400 size =    1.2920   98.7080\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:06<00:00, 48.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 4 acc = 10.6300 size =    0.0338   99.9662\n",
      "0.0 QuantizationScheme.NONE None 8\n",
      "0.5 QuantizationScheme.STATIC None None\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 31.1000 size =    4.6649   95.3351\n",
      "1.0 QuantizationScheme.DYNAMIC None 8\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 4 acc = 49.5600 size =    6.7329   93.2671\n",
      "0.6 QuantizationScheme.DYNAMIC None 8\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_CHANNEL, bitwidth = 2 acc = 9.7500 size =    0.6477   99.3523\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR None\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 13.6300 size =    0.4235   99.5765\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.DYNAMIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 31.0600 size =    4.6649   95.3351\n",
      "0.3 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "1.0 QuantizationScheme.NONE None 8\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.6 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n",
      "0.0 QuantizationScheme.NONE None 4\n",
      "0.6 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, scheme = QuantizationScheme.STATIC, granularity = QuantizationGranularity.PER_TENSOR, bitwidth = 8 acc = 27.0300 size =    4.6784   95.3216\n",
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█▉        | 62/313 [00:02<00:06, 38.08it/s]"
     ]
    }
   ],
   "source": [
    "sp = .1\n",
    "s = QuantizationScheme.DYNAMIC\n",
    "g = QuantizationGranularity.PER_TENSOR\n",
    "b = 4\n",
    "\n",
    "# for i in range(0, 11):\n",
    "#     sp = i/10\n",
    "\n",
    "# for i in [8, 4, 2]:\n",
    "\n",
    "#     b = i\n",
    "\n",
    "RANGE = 10\n",
    "for i in range(1000):\n",
    "    sp = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    s = random.choice([QuantizationScheme.NONE, QuantizationScheme.DYNAMIC, QuantizationScheme.DYNAMIC, QuantizationScheme.STATIC, QuantizationScheme.STATIC])\n",
    "    g = random.choice([None, QuantizationGranularity.PER_CHANNEL, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_TENSOR])\n",
    "    b = random.choice([None, 2, 4, 4, 8, 8])\n",
    "\n",
    "    print(sp, s, g, b)\n",
    "    compression_config = {\n",
    "        \n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : sp,\n",
    "            \"metric\" : \"l2\"\n",
    "        },\n",
    "\n",
    "        \"quantize\" : {\n",
    "            \"scheme\" : s,\n",
    "            \"granularity\": g,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "        # compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    # lenet5_mcu_model.cpu()\n",
    "    try:\n",
    "        compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    except ValueError:\n",
    "        continue\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "    # # compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "    # print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "    # print(\"#\"*40, \"Training\", \"#\"*40)\n",
    "    # early_stopper = EarlyStopper(\n",
    "    #     metric_name=\"validation_acc\",\n",
    "    #     min_valid_diff=.001,\n",
    "    #     mode=\"min\",\n",
    "    #     patience=3,\n",
    "    #     restore_best_state_dict=True,\n",
    "    # )\n",
    "\n",
    "    # criterion_fun = nn.CrossEntropyLoss()\n",
    "    # # optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    # compressed_lenet5_mcu_model.fit(\n",
    "    #     mnist_train_loader, \n",
    "    #     15, \n",
    "    #     criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    #     validation_dataloader=mnist_test_loader, \n",
    "    #     metrics={\"acc\": accuracy_fun},\n",
    "    #     verbose = True,\n",
    "    #     device=DEVICE,\n",
    "    #     callbacks = [early_stopper]\n",
    "    # )\n",
    "    # after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    # print(f\"After training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {after_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3e51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:03<00:00, 92.59it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97.49"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input_scale * weight_scale).view(1, -1, 1, 1)\n",
    "input_scale * weight_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d73749",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'compress'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      5\u001b[39m compression_config = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprune_channel\u001b[39m\u001b[33m\"\u001b[39m :{\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msparsity\u001b[39m\u001b[33m\"\u001b[39m : s\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m lenet5_mcu_model.cpu()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m compressed_lenet5_mcu_model = \u001b[43mlenet5_mcu_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompress\u001b[49m(compression_config, input_shape=input_shape, input_batch_real=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(mnist_test_loader))[\u001b[32m0\u001b[39m])\n\u001b[32m     18\u001b[39m compressed_lenet5_mcu_model.to(DEVICE)\n\u001b[32m     20\u001b[39m before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*\u001b[32m100\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1940\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1938\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1939\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1941\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1942\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Sequential' object has no attribute 'compress'"
     ]
    }
   ],
   "source": [
    "s = 0.5\n",
    "q = 3\n",
    "b = 8\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    # \"quantization\" : {\n",
    "    #     \"type\" : q,\n",
    "    #     \"bitwidth\" : b\n",
    "    # }\n",
    "\n",
    "}\n",
    "\n",
    "lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "s = 0.5\n",
    "q = 3\n",
    "b = 4\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    \"quantization\" : {\n",
    "        \"type\" : q,\n",
    "        \"bitwidth\" : b\n",
    "    }\n",
    "}\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = compressed_lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e02d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2343fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -4.2995,  -2.2290,  -1.3500,   7.7069,  -1.1915,  -1.9620, -12.2104,\n",
       "           -2.9040,  -1.8079,  -1.4910]], device='cuda:0'),\n",
       " tensor([[-1,  0,  0,  4,  0,  0, -5,  0,  0,  0]], device='cuda:0',\n",
       "        dtype=torch.int8))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model.test(device=DEVICE), \\\n",
    "quantize_per_tensor_assy(\n",
    "    compressed_lenet5_mcu_model.test(device=DEVICE),\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c44390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv2d_0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "  (relu6_0): ReLU6()\n",
       "  (maxpool2d_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2d_1): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu_0): ReLU()\n",
       "  (maxpool2d_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten_0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_0): Linear(in_features=400, out_features=84, bias=False)\n",
       "  (relu6_1): ReLU6()\n",
       "  (linear_1): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c49992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 28, 28])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0.]], grad_fn=<SliceBackward0>)\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3],\n",
      "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3]], dtype=torch.int8)\n",
      "torch.Size([1, 6, 14, 14])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=torch.int8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3, dtype=torch.int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_lenet5_mcu_model.cpu()\n",
    "test_input = compressed_lenet5_mcu_model.test_input.clone()\n",
    "\n",
    "test_input_quant = quantize_per_tensor_assy(\n",
    "    test_input,\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"],\n",
    ")\n",
    "\n",
    "test_input_real = dequantize_per_tensor_assy(\n",
    "    test_input_quant, \n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    ")\n",
    "\n",
    "i = 0\n",
    "# print(\"original real\", test_input[0,0,i])\n",
    "# print(\"quant real\", test_input_real[0,0,i])\n",
    "# print(\"quant\", test_input_quant[0,0,i])\n",
    "# line = torch.clamp(test_input[0,0,i]/compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"] + \\\n",
    "#                    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], -128, 127)\n",
    "# print(line)\n",
    "# print((line- compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]) * compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"])\n",
    "\n",
    "\n",
    "conv0 = compressed_lenet5_mcu_model[0]\n",
    "test_input_real = conv0(test_input_real)\n",
    "\n",
    "relu0 = compressed_lenet5_mcu_model[1]\n",
    "test_input_real = relu0(test_input_real)\n",
    "i = 5*2\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i:i+2])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i:i+2]\n",
    ")\n",
    "avgpool_0 = compressed_lenet5_mcu_model[2]\n",
    "test_input_real = avgpool_0(test_input_real)\n",
    "\n",
    "# flatten0 = compressed_lenet5_mcu_model[2]\n",
    "# test_input_real = flatten0(test_input_real)\n",
    "\n",
    "# linear0 = compressed_lenet5_mcu_model[3]\n",
    "# test_input_real = linear0(test_input_real)\n",
    "\n",
    "next_layer = compressed_lenet5_mcu_model[0]\n",
    "\n",
    "i = 5\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i]\n",
    ")\n",
    "\n",
    "# pad_input = nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     )\n",
    "# pad_weight = quant_weight.to(torch.int32)\n",
    "\n",
    "# quant_weight = quantize_per_tensor_sy(\n",
    "#         conv0.weight, \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#     )\n",
    "# test_input_quant = nn.functional.conv2d(\n",
    "#     nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     ),\n",
    "#     quant_weight.to(torch.int32),\n",
    "#     stride=5,\n",
    "# )\n",
    "\n",
    "# print(test_input_quant)\n",
    "# print(test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"])\n",
    "\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(test_input_real)\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_real,\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     nn.functional.conv2d(\n",
    "#         test_input_real, \n",
    "#         dequantize_per_tensor_sy(\n",
    "#             quant_weight,\n",
    "#                 conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#             ),\n",
    "#         stride=5\n",
    "#         # quantize_per_tensor_sy(\n",
    "#         #     conv0.weight, \n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#         # ).to(torch.int32),\n",
    "#         # stride=5,\n",
    "#     )\n",
    "\n",
    "# )\n",
    "# next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> 2bdec34589c4228cd2e25b041b1e1cc5407bd964
   "id": "ad66a75c",
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "IndentationError",
     "evalue": "unexpected indent (1965599166.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msparsity_per_layer = 0.25\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
=======
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number 0 ->  sparsity = 0.1, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 0, bitwidth = 8 acc = 97.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.40s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 133.46it/s]\n",
      "  1%|          | 1/100 [05:55<9:47:03, 355.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.00, bitwidth = 8 acc = 99.1800\n",
      "sample number 1 ->  sparsity = 0.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 128.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 8 acc = 99.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [01:59<05:28, 29.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 0 epoch with best train_loss = 0.0005885589403833971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.40it/s]\n",
      "  2%|▏         | 2/100 [08:00<5:58:39, 219.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.10, bitwidth = 8 acc = 99.1700\n",
      "sample number 2 ->  sparsity = 0.7, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, q_type = 1, bitwidth = 4 acc = 14.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:45<01:43, 25.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.06484621526400249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 139.05it/s]\n",
      "  3%|▎         | 3/100 [12:49<6:46:56, 251.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.20, bitwidth = 4 acc = 24.4900\n",
      "sample number 3 ->  sparsity = 0.2, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 8 acc = 96.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:35<03:08, 26.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.0017739665254640083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.70it/s]\n",
      "  4%|▍         | 4/100 [16:30<6:23:04, 239.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.30, bitwidth = 8 acc = 98.0000\n",
      "sample number 4 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:35<03:08, 26.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.0024001432311643537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.37it/s]\n",
      "  5%|▌         | 5/100 [20:10<6:08:11, 232.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.40, bitwidth = 4 acc = 97.6000\n",
      "sample number 5 ->  sparsity = 0.4, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 0, bitwidth = 8 acc = 57.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.35s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 138.53it/s]\n",
      "  6%|▌         | 6/100 [26:05<7:09:31, 274.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.50, bitwidth = 8 acc = 98.7700\n",
      "sample number 6 ->  sparsity = 0.6, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 0, bitwidth = 4 acc = 26.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:49<00:00, 23.28s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.24it/s]\n",
      "  7%|▋         | 7/100 [31:59<7:45:21, 300.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.60, bitwidth = 4 acc = 98.2300\n",
      "sample number 7 ->  sparsity = 0.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 4 acc = 98.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [02:48<04:12, 28.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 2 epoch with best train_loss = 0.000789507336853785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.68it/s]\n",
      "  8%|▊         | 8/100 [34:52<6:38:14, 259.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.70, bitwidth = 4 acc = 98.9700\n",
      "sample number 8 ->  sparsity = 0.5, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 0, bitwidth = 8 acc = 23.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.39s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 139.16it/s]\n",
      "  9%|▉         | 9/100 [40:48<7:19:18, 289.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.80, bitwidth = 8 acc = 98.3900\n",
      "sample number 9 ->  sparsity = 1.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 8 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:33<03:06, 26.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.07141990222533544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.77it/s]\n",
      " 10%|█         | 10/100 [44:26<6:41:25, 267.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.90, bitwidth = 8 acc = 14.1400\n",
      "sample number 10 ->  sparsity = 0.3, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 4 acc = 56.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:58<00:00, 23.92s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 138.33it/s]\n",
      " 11%|█         | 11/100 [50:30<7:20:31, 296.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.00, bitwidth = 4 acc = 83.1600\n",
      "sample number 11 ->  sparsity = 0.4, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 4 acc = 55.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:57<00:00, 23.86s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 135.22it/s]\n",
      " 12%|█▏        | 12/100 [56:32<7:44:52, 316.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.10, bitwidth = 4 acc = 78.8700\n",
      "sample number 12 ->  sparsity = 0.9, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 4 acc = 19.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:34<03:07, 26.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.06906819607814153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.52it/s]\n",
      " 13%|█▎        | 13/100 [1:00:12<6:56:44, 287.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.20, bitwidth = 4 acc = 18.9400\n",
      "sample number 13 ->  sparsity = 0.2, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 0, bitwidth = 4 acc = 97.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:05<01:16, 25.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.0006114612519836555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 121.00it/s]\n",
      " 14%|█▍        | 14/100 [1:05:22<7:01:54, 294.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.30, bitwidth = 4 acc = 99.0500\n",
      "sample number 14 ->  sparsity = 0.3, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 4 acc = 55.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:59<00:00, 23.97s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.23it/s]\n",
      " 15%|█▌        | 15/100 [1:11:26<7:26:50, 315.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.40, bitwidth = 4 acc = 82.5700\n",
      "sample number 15 ->  sparsity = 0.1, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 8 acc = 97.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:47<01:44, 26.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.0014350885208812543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.54it/s]\n",
      " 16%|█▌        | 16/100 [1:16:18<7:11:36, 308.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.50, bitwidth = 8 acc = 98.4900\n",
      "sample number 16 ->  sparsity = 0.5, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 131.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 4 acc = 20.9400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [05:35<00:51, 25.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 9 epoch with best train_loss = 0.03597152451872826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.56it/s]\n",
      " 17%|█▋        | 17/100 [1:21:58<7:19:33, 317.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.60, bitwidth = 4 acc = 60.7700\n",
      "sample number 17 ->  sparsity = 0.3, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 4 acc = 56.2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [05:34<00:51, 25.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 9 epoch with best train_loss = 0.016771014294773342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.05it/s]\n",
      " 18%|█▊        | 18/100 [1:27:37<7:23:14, 324.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.70, bitwidth = 4 acc = 82.6700\n",
      "sample number 18 ->  sparsity = 0.1, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 4 acc = 96.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [04:00<02:40, 26.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.001968830264398518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.29it/s]\n",
      " 19%|█▉        | 19/100 [1:31:42<6:45:35, 300.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.80, bitwidth = 4 acc = 97.9800\n",
      "sample number 19 ->  sparsity = 1.0, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 0, bitwidth = 8 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:48<00:00, 23.22s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 139.71it/s]\n",
      " 20%|██        | 20/100 [1:37:35<7:01:34, 316.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.90, bitwidth = 8 acc = 27.9800\n",
      "sample number 20 ->  sparsity = 0.7, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, q_type = 1, bitwidth = 8 acc = 15.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:46<01:44, 26.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.06572988899548848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.48it/s]\n",
      " 21%|██        | 21/100 [1:42:27<6:46:34, 308.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.00, bitwidth = 8 acc = 24.5900\n",
      "sample number 21 ->  sparsity = 0.2, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 8 acc = 96.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:35<03:08, 26.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.001786159169941675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.25it/s]\n",
      " 22%|██▏       | 22/100 [1:46:07<6:06:56, 282.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.10, bitwidth = 8 acc = 97.9500\n",
      "sample number 22 ->  sparsity = 0.4, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 126.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 4 acc = 55.3300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [05:35<00:51, 25.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 9 epoch with best train_loss = 0.02043263270954291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.42it/s]\n",
      " 23%|██▎       | 23/100 [1:51:47<6:24:27, 299.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.20, bitwidth = 4 acc = 78.4000\n",
      "sample number 23 ->  sparsity = 0.3, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 8 acc = 60.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [05:58<00:25, 25.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 10 epoch with best train_loss = 0.01481762630417943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.57it/s]\n",
      " 24%|██▍       | 24/100 [1:57:50<6:43:43, 318.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.30, bitwidth = 8 acc = 84.0000\n",
      "sample number 24 ->  sparsity = 0.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 8 acc = 99.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:12<01:18, 26.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.000566816997187713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.43it/s]\n",
      " 25%|██▌       | 25/100 [2:03:07<6:37:47, 318.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.40, bitwidth = 8 acc = 99.2600\n",
      "sample number 25 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 127.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 23.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:58<00:00, 23.93s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.32it/s]\n",
      " 26%|██▌       | 26/100 [2:09:11<6:49:19, 331.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.50, bitwidth = 8 acc = 60.4000\n",
      "sample number 26 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 23.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:10<01:17, 25.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.03669930265446504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.43it/s]\n",
      " 27%|██▋       | 27/100 [2:14:27<6:37:51, 327.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.60, bitwidth = 8 acc = 59.1700\n",
      "sample number 27 ->  sparsity = 1.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 4 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:33<03:06, 26.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.07151231505870818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.98it/s]\n",
      " 28%|██▊       | 28/100 [2:18:05<5:53:14, 294.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.70, bitwidth = 4 acc = 14.8900\n",
      "sample number 28 ->  sparsity = 0.1, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 4 acc = 96.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:12<03:40, 27.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 3 epoch with best train_loss = 0.001981406274092539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 120.55it/s]\n",
      " 29%|██▉       | 29/100 [2:21:23<5:13:58, 265.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.80, bitwidth = 4 acc = 98.0400\n",
      "sample number 29 ->  sparsity = 0.5, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 0, bitwidth = 4 acc = 23.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.42s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.99it/s]\n",
      " 30%|███       | 30/100 [2:27:19<5:41:17, 292.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 2.90, bitwidth = 4 acc = 98.6100\n",
      "sample number 30 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 122.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:36<03:09, 27.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.00238723942017726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.41it/s]\n",
      " 31%|███       | 31/100 [2:31:00<5:11:43, 271.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.00, bitwidth = 4 acc = 97.4100\n",
      "sample number 31 ->  sparsity = 0.3, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 119.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 4 acc = 56.2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [05:58<00:25, 25.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 10 epoch with best train_loss = 0.016753305385510127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.27it/s]\n",
      " 32%|███▏      | 32/100 [2:37:03<5:38:44, 298.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.10, bitwidth = 4 acc = 83.1600\n",
      "sample number 32 ->  sparsity = 0.1, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 4 acc = 96.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.0019463665115258967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.39it/s]\n",
      " 33%|███▎      | 33/100 [2:41:31<5:23:23, 289.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.20, bitwidth = 4 acc = 97.9900\n",
      "sample number 33 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 23.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [05:33<00:51, 25.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 9 epoch with best train_loss = 0.03679333200057348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.53it/s]\n",
      " 34%|███▍      | 34/100 [2:47:10<5:34:40, 304.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.30, bitwidth = 8 acc = 58.9500\n",
      "sample number 34 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.0023962142030824907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.74it/s]\n",
      " 35%|███▌      | 35/100 [2:51:38<5:17:54, 293.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.40, bitwidth = 4 acc = 97.3500\n",
      "sample number 35 ->  sparsity = 0.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 4 acc = 98.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.0007945449390168505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.85it/s]\n",
      " 36%|███▌      | 36/100 [2:56:07<5:05:03, 285.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.50, bitwidth = 4 acc = 99.0800\n",
      "sample number 36 ->  sparsity = 0.7, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, q_type = 1, bitwidth = 8 acc = 15.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:58<02:39, 26.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.065889085962375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.62it/s]\n",
      " 37%|███▋      | 37/100 [3:00:10<4:46:50, 273.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.60, bitwidth = 8 acc = 24.4400\n",
      "sample number 37 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:59<02:39, 26.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.0024244915310603875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 139.33it/s]\n",
      " 38%|███▊      | 38/100 [3:04:14<4:33:14, 264.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.70, bitwidth = 4 acc = 97.4400\n",
      "sample number 38 ->  sparsity = 0.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 8 acc = 99.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:24<04:48, 28.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 1 epoch with best train_loss = 0.0005621588824065233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.74it/s]\n",
      " 39%|███▉      | 39/100 [3:06:43<3:53:39, 229.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.80, bitwidth = 8 acc = 99.2900\n",
      "sample number 39 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 126.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:11<01:17, 25.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.0024129673541833955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.82it/s]\n",
      " 40%|████      | 40/100 [3:11:59<4:15:40, 255.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 3.90, bitwidth = 4 acc = 97.4900\n",
      "sample number 40 ->  sparsity = 0.7, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 126.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, q_type = 1, bitwidth = 8 acc = 15.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:58<00:00, 23.88s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 135.63it/s]\n",
      " 41%|████      | 41/100 [3:18:02<4:43:05, 287.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.00, bitwidth = 8 acc = 25.0100\n",
      "sample number 41 ->  sparsity = 0.4, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 8 acc = 58.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:10<01:17, 25.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.017886665488779544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.10it/s]\n",
      " 42%|████▏     | 42/100 [3:23:17<4:46:10, 296.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.10, bitwidth = 8 acc = 80.8800\n",
      "sample number 42 ->  sparsity = 1.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 128.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 4 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:33<03:07, 26.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.0715126963376999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.22it/s]\n",
      " 43%|████▎     | 43/100 [3:26:56<4:19:12, 272.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.20, bitwidth = 4 acc = 14.6800\n",
      "sample number 43 ->  sparsity = 0.9, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 0, bitwidth = 4 acc = 18.0300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:48<00:00, 23.20s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 138.12it/s]\n",
      " 44%|████▍     | 44/100 [3:32:49<4:37:02, 296.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.30, bitwidth = 4 acc = 86.7500\n",
      "sample number 44 ->  sparsity = 0.8, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 1, bitwidth = 4 acc = 15.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:21<02:10, 26.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.06604219512939453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.23it/s]\n",
      " 45%|████▌     | 45/100 [3:37:15<4:23:43, 287.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.40, bitwidth = 4 acc = 24.2900\n",
      "sample number 45 ->  sparsity = 0.3, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 0, bitwidth = 4 acc = 60.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:52<00:00, 23.47s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.84it/s]\n",
      " 46%|████▌     | 46/100 [3:43:12<4:37:33, 308.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.50, bitwidth = 4 acc = 98.8400\n",
      "sample number 46 ->  sparsity = 0.3, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 8 acc = 60.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:58<00:00, 23.90s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.75it/s]\n",
      " 47%|████▋     | 47/100 [3:49:15<4:46:55, 324.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.60, bitwidth = 8 acc = 84.8200\n",
      "sample number 47 ->  sparsity = 0.3, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 127.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 8 acc = 60.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:10<01:17, 25.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.01489437128379941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.85it/s]\n",
      " 48%|████▊     | 48/100 [3:54:30<4:39:05, 322.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.70, bitwidth = 8 acc = 84.5500\n",
      "sample number 48 ->  sparsity = 0.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 4 acc = 98.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:11<03:39, 27.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 3 epoch with best train_loss = 0.0007982280006428482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.05it/s]\n",
      " 49%|████▉     | 49/100 [3:57:47<4:01:42, 284.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.80, bitwidth = 4 acc = 98.9900\n",
      "sample number 49 ->  sparsity = 0.9, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 4 acc = 19.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:21<02:10, 26.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.06905851039489111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 131.07it/s]\n",
      " 50%|█████     | 50/100 [4:02:13<3:52:19, 278.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 4.90, bitwidth = 4 acc = 18.7200\n",
      "sample number 50 ->  sparsity = 0.9, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 4 acc = 19.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:22<02:11, 26.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.06902083293398222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.06it/s]\n",
      " 51%|█████     | 51/100 [4:06:40<3:44:45, 275.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.00, bitwidth = 4 acc = 18.2000\n",
      "sample number 51 ->  sparsity = 0.9, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 8 acc = 17.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [03:33<03:07, 26.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.06804542516271274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.33it/s]\n",
      " 52%|█████▏    | 52/100 [4:10:18<3:26:33, 258.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.10, bitwidth = 8 acc = 20.9900\n",
      "sample number 52 ->  sparsity = 1.0, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 126.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 0, bitwidth = 8 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:49<00:00, 23.27s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 132.62it/s]\n",
      " 53%|█████▎    | 53/100 [4:16:12<3:44:45, 286.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.20, bitwidth = 8 acc = 28.6500\n",
      "sample number 53 ->  sparsity = 0.6, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 0, bitwidth = 4 acc = 26.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.45s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.92it/s]\n",
      " 54%|█████▍    | 54/100 [4:22:08<3:55:57, 307.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.30, bitwidth = 4 acc = 98.4100\n",
      "sample number 54 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 23.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.03674712311923504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.29it/s]\n",
      " 55%|█████▌    | 55/100 [4:26:37<3:41:57, 295.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.40, bitwidth = 8 acc = 60.0100\n",
      "sample number 55 ->  sparsity = 0.1, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 4 acc = 95.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.00192719975936537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.65it/s]\n",
      " 56%|█████▌    | 56/100 [4:31:05<3:30:56, 287.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.50, bitwidth = 4 acc = 97.9800\n",
      "sample number 56 ->  sparsity = 0.8, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 1, bitwidth = 4 acc = 14.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:22<02:11, 26.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.06601963401436806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.17it/s]\n",
      " 57%|█████▋    | 57/100 [4:35:33<3:21:49, 281.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.60, bitwidth = 4 acc = 24.0200\n",
      "sample number 57 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.2900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [05:34<00:51, 25.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 9 epoch with best train_loss = 0.0024051418361642086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.00it/s]\n",
      " 58%|█████▊    | 58/100 [4:41:12<3:29:15, 298.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.70, bitwidth = 4 acc = 97.2600\n",
      "sample number 58 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 127.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.002377177127386676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.37it/s]\n",
      " 59%|█████▉    | 59/100 [4:45:40<3:17:56, 289.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.80, bitwidth = 4 acc = 97.3900\n",
      "sample number 59 ->  sparsity = 0.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 8 acc = 99.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [02:00<05:30, 30.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 0 epoch with best train_loss = 0.0006072483831372059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.14it/s]\n",
      " 60%|██████    | 60/100 [4:47:45<2:40:09, 240.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 5.90, bitwidth = 8 acc = 99.2000\n",
      "sample number 60 ->  sparsity = 0.4, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 8 acc = 58.0900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:59<00:00, 23.99s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.37it/s]\n",
      " 61%|██████    | 61/100 [4:53:49<3:00:24, 277.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.00, bitwidth = 8 acc = 82.1600\n",
      "sample number 61 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:23<02:11, 26.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.00242004320222574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 128.70it/s]\n",
      " 62%|██████▏   | 62/100 [4:58:18<2:54:03, 274.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.10, bitwidth = 4 acc = 97.4200\n",
      "sample number 62 ->  sparsity = 0.3, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 0, bitwidth = 8 acc = 60.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.39s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 133.40it/s]\n",
      " 63%|██████▎   | 63/100 [5:04:14<3:04:26, 299.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.20, bitwidth = 8 acc = 98.7700\n",
      "sample number 63 ->  sparsity = 0.8, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 1, bitwidth = 8 acc = 14.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:57<00:00, 23.84s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.08it/s]\n",
      " 64%|██████▍   | 64/100 [5:10:16<3:10:50, 318.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.30, bitwidth = 8 acc = 25.5500\n",
      "sample number 64 ->  sparsity = 0.2, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 127.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 0, bitwidth = 8 acc = 97.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.42s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 132.89it/s]\n",
      " 65%|██████▌   | 65/100 [5:16:12<3:12:13, 329.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.40, bitwidth = 8 acc = 99.1000\n",
      "sample number 65 ->  sparsity = 0.9, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 4 acc = 19.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:45<01:43, 25.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.06901559114257495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.84it/s]\n",
      " 66%|██████▌   | 66/100 [5:21:02<3:00:00, 317.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.50, bitwidth = 4 acc = 19.1800\n",
      "sample number 66 ->  sparsity = 0.4, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 131.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 8 acc = 58.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [05:59<00:25, 25.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 10 epoch with best train_loss = 0.0178375964636604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 126.40it/s]\n",
      " 67%|██████▋   | 67/100 [5:27:06<3:02:20, 331.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.60, bitwidth = 8 acc = 80.5800\n",
      "sample number 67 ->  sparsity = 0.8, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 0, bitwidth = 8 acc = 13.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.37s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.75it/s]\n",
      " 68%|██████▊   | 68/100 [5:33:02<3:00:37, 338.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.70, bitwidth = 8 acc = 96.1900\n",
      "sample number 68 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:24<02:12, 26.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.0024002515448257327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.51it/s]\n",
      " 69%|██████▉   | 69/100 [5:37:31<2:44:13, 317.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.80, bitwidth = 4 acc = 97.4400\n",
      "sample number 69 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.5400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:47<01:44, 26.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.0023708078098871434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.58it/s]\n",
      " 70%|███████   | 70/100 [5:42:23<2:35:08, 310.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 6.90, bitwidth = 4 acc = 97.5800\n",
      "sample number 70 ->  sparsity = 0.3, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 0, bitwidth = 4 acc = 60.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.47s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.77it/s]\n",
      " 71%|███████   | 71/100 [5:48:20<2:36:41, 324.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.00, bitwidth = 4 acc = 98.8200\n",
      "sample number 71 ->  sparsity = 0.1, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 118.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 8 acc = 97.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [04:00<02:40, 26.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.0014670277809045121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.96it/s]\n",
      " 72%|███████▏  | 72/100 [5:52:26<2:20:20, 300.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.10, bitwidth = 8 acc = 98.3500\n",
      "sample number 72 ->  sparsity = 0.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 4 acc = 98.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [02:48<04:13, 28.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 2 epoch with best train_loss = 0.0007787325321391108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.27it/s]\n",
      " 73%|███████▎  | 73/100 [5:55:20<1:58:10, 262.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.20, bitwidth = 4 acc = 99.0500\n",
      "sample number 73 ->  sparsity = 0.6, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 115.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 1, bitwidth = 4 acc = 24.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:58<00:00, 23.93s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.45it/s]\n",
      " 74%|███████▍  | 74/100 [6:01:24<2:06:59, 293.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.30, bitwidth = 4 acc = 53.9400\n",
      "sample number 74 ->  sparsity = 0.6, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 0, bitwidth = 4 acc = 26.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.38s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.17it/s]\n",
      " 75%|███████▌  | 75/100 [6:07:19<2:09:54, 311.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.40, bitwidth = 4 acc = 98.3400\n",
      "sample number 75 ->  sparsity = 0.8, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 116.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 0, bitwidth = 8 acc = 13.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.34s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.58it/s]\n",
      " 76%|███████▌  | 76/100 [6:13:14<2:09:55, 324.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.50, bitwidth = 8 acc = 96.0900\n",
      "sample number 76 ->  sparsity = 0.0, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 0, bitwidth = 8 acc = 99.3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:52<00:00, 23.52s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 132.08it/s]\n",
      " 77%|███████▋  | 77/100 [6:19:12<2:08:17, 334.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.60, bitwidth = 8 acc = 99.2400\n",
      "sample number 77 ->  sparsity = 0.5, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 0, bitwidth = 4 acc = 23.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.45s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 135.21it/s]\n",
      " 78%|███████▊  | 78/100 [6:25:09<2:05:06, 341.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.70, bitwidth = 4 acc = 98.6400\n",
      "sample number 78 ->  sparsity = 0.2, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 8 acc = 97.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:24<02:12, 26.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.0017811485328226506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.21it/s]\n",
      " 79%|███████▉  | 79/100 [6:29:38<1:51:51, 319.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.80, bitwidth = 8 acc = 98.0400\n",
      "sample number 79 ->  sparsity = 1.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 4 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [02:46<04:09, 27.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 2 epoch with best train_loss = 0.07153036953210831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.66it/s]\n",
      " 80%|████████  | 80/100 [6:32:29<1:31:41, 275.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 7.90, bitwidth = 4 acc = 14.5900\n",
      "sample number 80 ->  sparsity = 1.0, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 0, bitwidth = 4 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:50<00:00, 23.37s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.05it/s]\n",
      " 81%|████████  | 81/100 [6:38:24<1:34:43, 299.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.00, bitwidth = 4 acc = 28.8000\n",
      "sample number 81 ->  sparsity = 0.6, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 129.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 1, bitwidth = 4 acc = 24.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:12<01:18, 26.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.04310357688764731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.23it/s]\n",
      " 82%|████████▏ | 82/100 [6:43:41<1:31:21, 304.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.10, bitwidth = 4 acc = 51.8800\n",
      "sample number 82 ->  sparsity = 1.0, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 0, bitwidth = 8 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:51<00:00, 23.41s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 136.45it/s]\n",
      " 83%|████████▎ | 83/100 [6:49:37<1:30:38, 319.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.20, bitwidth = 8 acc = 27.9700\n",
      "sample number 83 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 95.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:12<03:39, 27.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 3 epoch with best train_loss = 0.0024367216873603563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.11it/s]\n",
      " 84%|████████▍ | 84/100 [6:52:55<1:15:30, 283.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.30, bitwidth = 4 acc = 97.5300\n",
      "sample number 84 ->  sparsity = 0.1, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 128.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, q_type = 1, bitwidth = 8 acc = 97.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [04:00<02:40, 26.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.0014361177437773828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.99it/s]\n",
      " 85%|████████▌ | 85/100 [6:57:00<1:07:58, 271.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.40, bitwidth = 8 acc = 98.4400\n",
      "sample number 85 ->  sparsity = 0.3, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 1, bitwidth = 8 acc = 60.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [04:47<01:44, 26.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.014857118554910023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.07it/s]\n",
      " 86%|████████▌ | 86/100 [7:01:53<1:04:53, 278.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.50, bitwidth = 8 acc = 84.5400\n",
      "sample number 86 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 23.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:58<00:00, 23.91s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.75it/s]\n",
      " 87%|████████▋ | 87/100 [7:07:56<1:05:47, 303.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.60, bitwidth = 8 acc = 60.5300\n",
      "sample number 87 ->  sparsity = 0.9, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 112.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 4 acc = 19.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:57<02:38, 26.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.06902700161337852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.41it/s]\n",
      " 88%|████████▊ | 88/100 [7:11:59<57:06, 285.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.70, bitwidth = 4 acc = 18.8800\n",
      "sample number 88 ->  sparsity = 0.4, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 127.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 4 acc = 55.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [04:24<02:12, 26.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.020557275403290987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.96it/s]\n",
      " 89%|████████▉ | 89/100 [7:16:29<51:27, 280.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.80, bitwidth = 4 acc = 77.9800\n",
      "sample number 89 ->  sparsity = 0.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 8 acc = 99.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [02:24<04:48, 28.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 1 epoch with best train_loss = 0.000557124045934385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 131.64it/s]\n",
      " 90%|█████████ | 90/100 [7:18:58<40:12, 241.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 8.90, bitwidth = 8 acc = 99.1000\n",
      "sample number 90 ->  sparsity = 0.0, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 133.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 0, bitwidth = 4 acc = 99.1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:59<00:00, 23.98s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.06it/s]\n",
      " 91%|█████████ | 91/100 [7:25:02<41:43, 278.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.00, bitwidth = 4 acc = 99.1200\n",
      "sample number 91 ->  sparsity = 0.0, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 0, bitwidth = 4 acc = 99.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:53<00:00, 23.58s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 137.22it/s]\n",
      " 92%|█████████▏| 92/100 [7:31:01<40:18, 302.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.10, bitwidth = 4 acc = 99.2800\n",
      "sample number 92 ->  sparsity = 0.9, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 128.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, q_type = 1, bitwidth = 8 acc = 18.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [05:09<01:17, 25.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.06800669422547022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.66it/s]\n",
      " 93%|█████████▎| 93/100 [7:36:15<35:41, 305.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.20, bitwidth = 8 acc = 21.4400\n",
      "sample number 93 ->  sparsity = 0.5, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 0, bitwidth = 4 acc = 23.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:53<00:00, 23.57s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.34it/s]\n",
      " 94%|█████████▍| 94/100 [7:42:14<32:09, 321.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.30, bitwidth = 4 acc = 98.6400\n",
      "sample number 94 ->  sparsity = 1.0, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 4 acc = 9.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [03:11<03:39, 27.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 3 epoch with best train_loss = 0.07151553703943889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 136.76it/s]\n",
      " 95%|█████████▌| 95/100 [7:45:30<23:40, 284.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.40, bitwidth = 4 acc = 14.9900\n",
      "sample number 95 ->  sparsity = 0.5, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 131.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 0, bitwidth = 8 acc = 23.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:52<00:00, 23.47s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 133.23it/s]\n",
      " 96%|█████████▌| 96/100 [7:51:27<20:23, 305.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.50, bitwidth = 8 acc = 98.7300\n",
      "sample number 96 ->  sparsity = 0.6, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 125.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 1, bitwidth = 8 acc = 26.9600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:59<00:00, 23.94s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 138.01it/s]\n",
      " 97%|█████████▋| 97/100 [7:57:31<16:10, 323.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.60, bitwidth = 8 acc = 53.8200\n",
      "sample number 97 ->  sparsity = 0.6, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 135.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 1, bitwidth = 8 acc = 26.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [06:08<00:00, 24.54s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 132.62it/s]\n",
      " 98%|█████████▊| 98/100 [8:03:44<11:16, 338.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.70, bitwidth = 8 acc = 51.6300\n",
      "sample number 98 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 134.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 23.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [05:58<00:25, 25.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 10 epoch with best train_loss = 0.03673108915388584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 138.39it/s]\n",
      " 99%|█████████▉| 99/100 [8:09:47<05:45, 345.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.80, bitwidth = 8 acc = 58.3100\n",
      "sample number 99 ->  sparsity = 0.4, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 128.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 0, bitwidth = 4 acc = 58.0200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [06:07<00:00, 24.51s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 134.91it/s]\n",
      "100%|██████████| 100/100 [8:16:00<00:00, 297.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 9.90, bitwidth = 4 acc = 98.8300\n"
>>>>>>> 2bdec34589c4228cd2e25b041b1e1cc5407bd964
     ]
    }
   ],
   "source": [
    " sparsity_per_layer = 0.25\n",
    "RANGE = 10\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "if not os.path.exists(log_compression_details_file):\n",
    "    with open(log_compression_details_file, \"w\") as file:\n",
    "        file.write(f\"sparsity, quantization_type, bitwidth, size, size_ratio, before acc, after acc, before acc_drop, after acc_drop\\n\")\n",
    "        # file.write(f\"sparsity, quantizaion_type, bitwidth, before acc, after acc\\n\")\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    # s = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    # q = random.choice([QUANTIZATION_NONE, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR])\n",
    "    # b = random.choice([4, 8])\n",
    "    # print(f\"sample number {i} ->  sparsity = {s}, q_type = {q}, bitwidth = {b}\")\n",
    "\n",
    "    s = 0.\n",
    "    q = 1\n",
    "    b = 8\n",
    "\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : s\n",
    "        },\n",
    "        \"quantization\" : {\n",
    "            \"type\" : q,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    lenet5_mcu_model.cpu()\n",
    "    compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape)\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    compressed_lenet5_mcu_model.cpu()\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f}\")\n",
    "\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-5,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    compressed_lenet5_mcu_model.fit(\n",
    "        mnist_train_loader, \n",
    "        15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        verbose = False,\n",
    "        device=DEVICE,\n",
    "        compression_config=compression_config,\n",
    "        callbacks = [early_stopper]\n",
    "    )\n",
    "    after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    print(f\"After training, sparsity = {i/RANGE:.2f}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "    with open(log_compression_details_file, \"a\") as file:\n",
    "        file.write(f\"{s}, {q}, {b}, {size}, {size/original_size*100:9.4f}, {before_acc:9.4f}, {after_acc:9.4f}, {original_acc-before_acc:9.4f}, {original_acc-after_acc:9.4f}\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5278080",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (970928641.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msparsity_per_layer = 0.1\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " sparsity_per_layer = 0.1\n",
    "lenet5_model.to(\"cpu\")\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "# acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "# print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.to(DEVICE)\n",
    "lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=DEVICE,\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10372455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
