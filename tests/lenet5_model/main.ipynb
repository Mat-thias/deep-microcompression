{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df77885",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    AvgPool2d,\n",
    "    BatchNorm2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    ReLU6,\n",
    "    MaxPool2d,\n",
    "    Flatten, \n",
    "\n",
    "    EarlyStopper,\n",
    "    quantize_per_tensor_assy,\n",
    "    quantize_per_tensor_sy,\n",
    "    dequantize_per_tensor_assy,\n",
    "    dequantize_per_tensor_sy,\n",
    "    \n",
    "    QuantizationGranularity,\n",
    "    QuantizationScaleType,\n",
    "    QuantizationScheme\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1bf3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = f\"lenet5_state_dict.pth\"\n",
    "log_compression_details_file = \"lenet5_compression_log.csv\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 28, 28)\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize(input_shape[1:]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"../../../Datasets/\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"../../../Datasets/\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32, shuffle=False, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=tuple([2]*4), bias=False),\n",
    "    # BatchNorm2d(num_features=6),\n",
    "    ReLU6(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    # BatchNorm2d(num_features=16),\n",
    "    ReLU(),\n",
    "    # ReLU6(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "    # AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "    \n",
    "    Linear(in_features=16*5*5, out_features=84, bias=False),\n",
    "    ReLU6(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f8fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=5, pad=[2]*4, bias=True),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Conv2d(in_channels=6, out_channels=3, kernel_size=1, stride=1, pad=[0]*4, bias=False),\n",
    "#     MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*3*3, out_features=84, bias=False),\n",
    "#     ReLU(),\n",
    "#     Linear(in_features=84, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b811aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=5, pad=[2]*4, bias=False),\n",
    "#     # BatchNorm2d(num_features=3),\n",
    "#     ReLU(),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*6*6, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed228ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      3\u001b[39m lenet5_model.cpu()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mlenet5_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlenet5_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m lenet5_model.to(DEVICE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for Sequential:\n\tMissing key(s) in state_dict: \"linear_0.bias\". \n\tUnexpected key(s) in state_dict: \"conv2d_1.weight\", \"conv2d_1.bias\", \"linear_1.weight\", \"linear_1.bias\". \n\tsize mismatch for conv2d_0.weight: copying a param with shape torch.Size([6, 1, 5, 5]) from checkpoint, the shape in current model is torch.Size([3, 1, 3, 3]).\n\tsize mismatch for linear_0.weight: copying a param with shape torch.Size([84, 400]) from checkpoint, the shape in current model is torch.Size([10, 108]).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=\u001b[32m1.e-3\u001b[39m)\n\u001b[32m     18\u001b[39m lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mlenet5_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmnist_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizion_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmnist_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43macc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fun\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m lenet5_model.cpu()\n\u001b[32m     29\u001b[39m torch.save(lenet5_model.state_dict(), lenet5_file)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/models/sequential.py:150\u001b[39m, in \u001b[36mSequential.fit\u001b[39m\u001b[34m(self, train_dataloader, epochs, criterion_fun, optimizer_fun, lr_scheduler, validation_dataloader, metrics, verbose, callbacks, device)\u001b[39m\n\u001b[32m    147\u001b[39m         metrics_val[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mself\u001b[39m.train()\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/queues.py:122\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    120\u001b[39m         \u001b[38;5;28mself\u001b[39m._rlock.release()\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ForkingPickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/multiprocessing/reductions.py:541\u001b[39m, in \u001b[36mrebuild_storage_fd\u001b[39m\u001b[34m(cls, df, size)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrebuild_storage_fd\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, size):\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     fd = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    543\u001b[39m         storage = storage_from_cache(\u001b[38;5;28mcls\u001b[39m, fd_id(fd))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/resource_sharer.py:57\u001b[39m, in \u001b[36mDupFd.detach\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetach\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     56\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Get the fd.  This should only be called once.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_resource_sharer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m reduction.recv_handle(conn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/resource_sharer.py:86\u001b[39m, in \u001b[36m_ResourceSharer.get_connection\u001b[39m\u001b[34m(ident)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconnection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m     85\u001b[39m address, key = ident\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m c = \u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m c.send((key, os.getpid()))\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:525\u001b[39m, in \u001b[36mClient\u001b[39m\u001b[34m(address, family, authkey)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mauthkey should be a byte string\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    524\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m authkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     \u001b[43manswer_challenge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauthkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m     deliver_challenge(c, authkey)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:949\u001b[39m, in \u001b[36manswer_challenge\u001b[39m\u001b[34m(connection, authkey)\u001b[39m\n\u001b[32m    945\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    946\u001b[39m         connection.send_bytes(_WELCOME)\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34manswer_challenge\u001b[39m(connection, authkey: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m    950\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(authkey, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    952\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAuthkey must be bytes, not \u001b[39m\u001b[38;5;132;01m{0!s}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(authkey)))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.cpu()\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True), strict=True)\n",
    "    lenet5_model.to(DEVICE)\n",
    "\n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-7,\n",
    "        mode=\"min\",\n",
    "        patience=2,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 2, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\" : accuracy_fun},\n",
    "        callbacks=[early_stopper],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    lenet5_model.cpu()\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    lenet5_model.to(DEVICE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 77.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.33\n",
      "The original model accuracy is 99.33% with size 148064 bytes.\n",
      "tensor([[ -0.2030, -15.9340,  -5.2494,  -8.3431, -11.0375,  -0.6326,  12.5557,\n",
      "         -23.4996,  -6.0131,  -8.0073]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9933, 148064)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(original_acc*100)\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n",
    "print(lenet5_mcu_model.test(device=DEVICE))\n",
    "original_acc, original_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3f894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x741162e9cf50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3978d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 4 acc = 89.7200 size =    6.7984   93.2016\n",
      "compressed_lenet5_mcu_model_0.3_STATIC_PER_TENSOR_4\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 8 acc = 94.7100 size =   13.5232   86.4768\n",
      "compressed_lenet5_mcu_model_0.3_STATIC_PER_TENSOR_8\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:08<00:00, 36.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 4 acc = 43.4000 size =    3.2689   96.7311\n",
      "compressed_lenet5_mcu_model_0.5_STATIC_PER_TENSOR_4\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.6983   99.3017\n",
      "compressed_lenet5_mcu_model_0.7_STATIC_PER_TENSOR_2\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 47.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = DYNAMIC, granularity = PER_CHANNEL, bitwidth = 4 acc = 19.6500 size =    3.2128   96.7872\n",
      "compressed_lenet5_mcu_model_0.5_DYNAMIC_PER_CHANNEL_4\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:10<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = STATIC, granularity = PER_CHANNEL, bitwidth = 8 acc = 9.8000 size =   16.6428   83.3572\n",
      "compressed_lenet5_mcu_model_0.2_STATIC_PER_CHANNEL_8\n",
      "0.5 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 59.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 8 acc = 39.3300 size =    6.4249   93.5751\n",
      "compressed_lenet5_mcu_model_0.5_DYNAMIC_PER_TENSOR_8\n",
      "0.6 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 8 acc = 98.9600 size =   21.4637   78.5363\n",
      "compressed_lenet5_mcu_model_0.1_STATIC_PER_TENSOR_8\n",
      "0.5 QuantizationScheme.DYNAMIC None 4\n",
      "0.9 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 8 acc = 14.1000 size =    0.4613   99.5387\n",
      "compressed_lenet5_mcu_model_0.9_STATIC_PER_TENSOR_8\n",
      "0.9 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 8\n",
      "0.3 QuantizationScheme.DYNAMIC None None\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 8 acc = 66.4900 size =    9.7660   90.2340\n",
      "compressed_lenet5_mcu_model_0.4_STATIC_PER_TENSOR_8\n",
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 34.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 8 acc = 65.8900 size =    9.7660   90.2340\n",
      "compressed_lenet5_mcu_model_0.4_STATIC_PER_TENSOR_8\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:04<00:00, 64.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 8 acc = 20.7200 size =    1.4413   98.5587\n",
      "compressed_lenet5_mcu_model_0.8_DYNAMIC_PER_TENSOR_8\n",
      "0.4 QuantizationScheme.STATIC None None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL None\n",
      "0.8 QuantizationScheme.STATIC None None\n",
      "0.7 QuantizationScheme.STATIC None None\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 57.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    0.0189   99.9811\n",
      "compressed_lenet5_mcu_model_1.0_DYNAMIC_PER_TENSOR_2\n",
      "0.4 QuantizationScheme.STATIC None 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 4 acc = 65.9000 size =    4.9168   95.0832\n",
      "compressed_lenet5_mcu_model_0.4_STATIC_PER_TENSOR_4\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 4\n",
      "0.8 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 61.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 8 acc = 20.5800 size =    1.4413   98.5587\n",
      "compressed_lenet5_mcu_model_0.8_DYNAMIC_PER_TENSOR_8\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 27.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, scheme = STATIC, granularity = PER_CHANNEL, bitwidth = 8 acc = 9.8000 size =    9.7660   90.2340\n",
      "compressed_lenet5_mcu_model_0.4_STATIC_PER_CHANNEL_8\n",
      "0.1 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:08<00:00, 34.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.1, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 4 acc = 96.5900 size =   10.7724   89.2276\n",
      "compressed_lenet5_mcu_model_0.1_STATIC_PER_TENSOR_4\n",
      "0.2 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:09<00:00, 33.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 8 acc = 97.5400 size =   16.6428   83.3572\n",
      "compressed_lenet5_mcu_model_0.2_STATIC_PER_TENSOR_8\n",
      "0.1 QuantizationScheme.STATIC None None\n",
      "0.7 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, scheme = DYNAMIC, granularity = PER_CHANNEL, bitwidth = 8 acc = 13.2900 size =    2.5833   97.4167\n",
      "compressed_lenet5_mcu_model_0.7_DYNAMIC_PER_CHANNEL_8\n",
      "1.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:04<00:00, 62.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 8 acc = 13.1300 size =    0.0648   99.9352\n",
      "compressed_lenet5_mcu_model_1.0_DYNAMIC_PER_TENSOR_8\n",
      "0.9 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:05<00:00, 53.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.9, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 8 acc = 13.4300 size =    0.4235   99.5765\n",
      "compressed_lenet5_mcu_model_0.9_DYNAMIC_PER_TENSOR_8\n",
      "0.2 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 8\n",
      "0.1 QuantizationScheme.NONE QuantizationGranularity.PER_TENSOR 2\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 2 acc = 9.8000 size =    3.3675   96.6325\n",
      "compressed_lenet5_mcu_model_0.3_DYNAMIC_PER_TENSOR_2\n",
      "0.0 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:11<00:00, 28.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, scheme = STATIC, granularity = PER_CHANNEL, bitwidth = 8 acc = 26.9100 size =   25.0662   74.9338\n",
      "compressed_lenet5_mcu_model_0.0_STATIC_PER_CHANNEL_8\n",
      "0.5 QuantizationScheme.STATIC QuantizationGranularity.PER_CHANNEL 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 313/313 [00:11<00:00, 28.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, scheme = STATIC, granularity = PER_CHANNEL, bitwidth = 8 acc = 9.8000 size =    6.4749   93.5251\n",
      "compressed_lenet5_mcu_model_0.5_STATIC_PER_CHANNEL_8\n",
      "0.8 QuantizationScheme.NONE QuantizationGranularity.PER_CHANNEL 4\n",
      "0.3 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 55.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = DYNAMIC, granularity = PER_TENSOR, bitwidth = 4 acc = 93.9100 size =    6.7329   93.2671\n",
      "compressed_lenet5_mcu_model_0.3_DYNAMIC_PER_TENSOR_4\n",
      "0.3 QuantizationScheme.STATIC QuantizationGranularity.PER_TENSOR 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:09<00:00, 34.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, scheme = STATIC, granularity = PER_TENSOR, bitwidth = 4 acc = 89.8100 size =    6.7984   93.2016\n",
      "compressed_lenet5_mcu_model_0.3_STATIC_PER_TENSOR_4\n",
      "0.0 QuantizationScheme.DYNAMIC QuantizationGranularity.PER_CHANNEL 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 235/313 [00:05<00:01, 46.83it/s]"
     ]
    }
   ],
   "source": [
    "sp = .1\n",
    "s = QuantizationScheme.STATIC\n",
    "g = QuantizationGranularity.PER_TENSOR\n",
    "b = 4\n",
    "\n",
    "# for i in range(0, 11):\n",
    "#     sp = i/10\n",
    "\n",
    "# for i in [8, 4, 2]:\n",
    "\n",
    "#     b = i\n",
    "\n",
    "RANGE = 10\n",
    "for i in range(1000):\n",
    "    sp = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    s = random.choice([QuantizationScheme.NONE, QuantizationScheme.DYNAMIC, QuantizationScheme.DYNAMIC, QuantizationScheme.STATIC, QuantizationScheme.STATIC])\n",
    "    g = random.choice([None, QuantizationGranularity.PER_CHANNEL, QuantizationGranularity.PER_CHANNEL, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_TENSOR, QuantizationGranularity.PER_TENSOR])\n",
    "    b = random.choice([None, 2, 4, 4, 8, 8])\n",
    "\n",
    "    print(sp, s, g, b)\n",
    "    compression_config = {\n",
    "        \n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : sp,\n",
    "            \"metric\" : \"l2\"\n",
    "        },\n",
    "\n",
    "        \"quantize\" : {\n",
    "            \"scheme\" : s,\n",
    "            \"granularity\": g,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "        # compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    # lenet5_mcu_model.cpu()\n",
    "    try:\n",
    "        compressed_lenet5_mcu_model = lenet5_mcu_model.init_compress(compression_config, input_shape=input_shape, calibration_data=next(iter(mnist_test_loader))[0].to(DEVICE))\n",
    "    except ValueError:\n",
    "        continue\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "    try:\n",
    "        print(f\"Before training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "    except AttributeError:\n",
    "        print(f\"Before training, sparsity = {sp}, scheme = {s}, granularity = {g}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f} {100 - size/original_size*100:9.4f}\")\n",
    "        \n",
    "    # # compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "    # print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "    # print(\"#\"*40, \"Training\", \"#\"*40)\n",
    "    # early_stopper = EarlyStopper(\n",
    "    #     metric_name=\"validation_acc\",\n",
    "    #     min_valid_diff=.001,\n",
    "    #     mode=\"min\",\n",
    "    #     patience=3,\n",
    "    #     restore_best_state_dict=True,\n",
    "    # )\n",
    "\n",
    "    # criterion_fun = nn.CrossEntropyLoss()\n",
    "    # # optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    # lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    # compressed_lenet5_mcu_model.fit(\n",
    "    #     mnist_train_loader, \n",
    "    #     15, \n",
    "    #     criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    #     validation_dataloader=mnist_test_loader, \n",
    "    #     metrics={\"acc\": accuracy_fun},\n",
    "    #     verbose = True,\n",
    "    #     device=DEVICE,\n",
    "    #     callbacks = [early_stopper]\n",
    "    # )\n",
    "    # after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "    try:\n",
    "        # print(f\"After training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "        print(f\"compressed_lenet5_mcu_model_{sp}_{s.name}_{g.name}_{b}\")\n",
    "    except AttributeError:\n",
    "        # print(f\"After training, sparsity = {sp}, scheme = {s.name}, granularity = {g.name}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "        print(f\"compressed_lenet5_mcu_model_{sp}_{s}_{g}_{b}\")\n",
    "    # compressed_lenet5_mcu_model.cpu()\n",
    "    # torch.save(compressed_lenet5_mcu_model, f\"compressed_lenet5_mcu_model_{sp}_{s}_{q}_{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_scale * weight_scale).view(1, -1, 1, 1)\n",
    "input_scale * weight_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d73749",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0.5\n",
    "q = 3\n",
    "b = 8\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    # \"quantization\" : {\n",
    "    #     \"type\" : q,\n",
    "    #     \"bitwidth\" : b\n",
    "    # }\n",
    "\n",
    "}\n",
    "\n",
    "lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "s = 0.5\n",
    "q = 3\n",
    "b = 4\n",
    "\n",
    "compression_config = {\n",
    "    \"prune_channel\" :{\n",
    "        \"sparsity\" : s\n",
    "    },\n",
    "    \"quantization\" : {\n",
    "        \"type\" : q,\n",
    "        \"bitwidth\" : b\n",
    "    }\n",
    "}\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model = compressed_lenet5_mcu_model.compress(compression_config, input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0])\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f} size = {size/original_size*100:9.4f}\")\n",
    "compressed_lenet5_mcu_model.cpu()\n",
    "compressed_lenet5_mcu_model.convert_to_c(input_shape=input_shape, var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "compressed_lenet5_mcu_model.to(DEVICE)\n",
    "# print(compressed_lenet5_mcu_model.test(device=DEVICE))\n",
    "\n",
    "early_stopper = EarlyStopper(\n",
    "    metric_name=\"train_loss\",\n",
    "    min_valid_diff=1e-5,\n",
    "    mode=\"min\",\n",
    "    patience=4,\n",
    "    restore_best_state_dict=True,\n",
    ")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "# optimizion_fun = optim.SGD(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=10.e-3)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "compressed_lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    verbose = True,\n",
    "    device=DEVICE,\n",
    "    compression_config=compression_config,\n",
    "    input_shape=input_shape, input_batch_real=next(iter(mnist_test_loader))[0],\n",
    "    callbacks = [early_stopper]\n",
    ")\n",
    "after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "print(f\"After training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {after_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e02d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2343fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_lenet5_mcu_model.test(device=DEVICE), \\\n",
    "quantize_per_tensor_assy(\n",
    "    compressed_lenet5_mcu_model.test(device=DEVICE),\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "    compressed_lenet5_mcu_model[-1].__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c44390",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_lenet5_mcu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c49992",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_lenet5_mcu_model.cpu()\n",
    "test_input = compressed_lenet5_mcu_model.test_input.clone()\n",
    "\n",
    "test_input_quant = quantize_per_tensor_assy(\n",
    "    test_input,\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"],\n",
    ")\n",
    "\n",
    "test_input_real = dequantize_per_tensor_assy(\n",
    "    test_input_quant, \n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"],\n",
    "    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"],\n",
    ")\n",
    "\n",
    "i = 0\n",
    "# print(\"original real\", test_input[0,0,i])\n",
    "# print(\"quant real\", test_input_real[0,0,i])\n",
    "# print(\"quant\", test_input_quant[0,0,i])\n",
    "# line = torch.clamp(test_input[0,0,i]/compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"] + \\\n",
    "#                    compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], -128, 127)\n",
    "# print(line)\n",
    "# print((line- compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]) * compressed_lenet5_mcu_model.__dict__[\"_dmc\"][\"quantization\"][\"input_scale\"])\n",
    "\n",
    "\n",
    "conv0 = compressed_lenet5_mcu_model[0]\n",
    "test_input_real = conv0(test_input_real)\n",
    "\n",
    "relu0 = compressed_lenet5_mcu_model[1]\n",
    "test_input_real = relu0(test_input_real)\n",
    "i = 5*2\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i:i+2])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i:i+2]\n",
    ")\n",
    "avgpool_0 = compressed_lenet5_mcu_model[2]\n",
    "test_input_real = avgpool_0(test_input_real)\n",
    "\n",
    "# flatten0 = compressed_lenet5_mcu_model[2]\n",
    "# test_input_real = flatten0(test_input_real)\n",
    "\n",
    "# linear0 = compressed_lenet5_mcu_model[3]\n",
    "# test_input_real = linear0(test_input_real)\n",
    "\n",
    "next_layer = compressed_lenet5_mcu_model[0]\n",
    "\n",
    "i = 5\n",
    "print(test_input_real.size())\n",
    "print(test_input_real[0,0,i])\n",
    "print(\n",
    "    quantize_per_tensor_assy(\n",
    "        test_input_real,\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "        next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "    )[0,0,i]\n",
    ")\n",
    "\n",
    "# pad_input = nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     )\n",
    "# pad_weight = quant_weight.to(torch.int32)\n",
    "\n",
    "# quant_weight = quantize_per_tensor_sy(\n",
    "#         conv0.weight, \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#     )\n",
    "# test_input_quant = nn.functional.conv2d(\n",
    "#     nn.functional.pad(\n",
    "#         test_input_quant.to(torch.int32) - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"], \n",
    "#         conv0.pad, \n",
    "#         \"constant\", \n",
    "#         conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"] - conv0.__dict__[\"_dmc\"][\"quantization\"][\"input_zero_point\"]\n",
    "#     ),\n",
    "#     quant_weight.to(torch.int32),\n",
    "#     stride=5,\n",
    "# )\n",
    "\n",
    "# print(test_input_quant)\n",
    "# print(test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"])\n",
    "\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_quant*next_layer.__dict__[\"_dmc\"][\"quantization\"][\"bias_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(test_input_real)\n",
    "# print(\n",
    "#     quantize_per_tensor_assy(\n",
    "#         test_input_real,\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_scale\"],\n",
    "#         next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(\n",
    "#     nn.functional.conv2d(\n",
    "#         test_input_real, \n",
    "#         dequantize_per_tensor_sy(\n",
    "#             quant_weight,\n",
    "#                 conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#             ),\n",
    "#         stride=5\n",
    "#         # quantize_per_tensor_sy(\n",
    "#         #     conv0.weight, \n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"weight_scale\"],\n",
    "#         #     conv0.__dict__[\"_dmc\"][\"quantization\"][\"bitwidth\"]\n",
    "#         # ).to(torch.int32),\n",
    "#         # stride=5,\n",
    "#     )\n",
    "\n",
    "# )\n",
    "# next_layer.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]\n",
    "conv0.__dict__[\"_dmc\"][\"quantization\"][\"output_zero_point\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    " sparsity_per_layer = 0.25\n",
    "RANGE = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(log_compression_details_file):\n",
    "    with open(log_compression_details_file, \"w\") as file:\n",
    "        file.write(f\"sparsity, quantization_type, bitwidth, size, size_ratio, before acc, after acc, before acc_drop, after acc_drop\\n\")\n",
    "        # file.write(f\"sparsity, quantizaion_type, bitwidth, before acc, after acc\\n\")\n",
    "\n",
    "for i in tqdm(range(1)):\n",
    "\n",
    "    # s = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    # q = random.choice([QUANTIZATION_NONE, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR])\n",
    "    # b = random.choice([4, 8])\n",
    "    # print(f\"sample number {i} ->  sparsity = {s}, q_type = {q}, bitwidth = {b}\")\n",
    "\n",
    "    s = 0.\n",
    "    q = 1\n",
    "    b = 8\n",
    "\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : s\n",
    "        },\n",
    "        \"quantization\" : {\n",
    "            \"type\" : q,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    lenet5_mcu_model.cpu()\n",
    "    compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=input_shape)\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    compressed_lenet5_mcu_model.cpu()\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f}\")\n",
    "\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-5,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    compressed_lenet5_mcu_model.fit(\n",
    "        mnist_train_loader, \n",
    "        15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        verbose = False,\n",
    "        device=DEVICE,\n",
    "        compression_config=compression_config,\n",
    "        callbacks = [early_stopper]\n",
    "    )\n",
    "    after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    print(f\"After training, sparsity = {i/RANGE:.2f}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "    with open(log_compression_details_file, \"a\") as file:\n",
    "        file.write(f\"{s}, {q}, {b}, {size}, {size/original_size*100:9.4f}, {before_acc:9.4f}, {after_acc:9.4f}, {original_acc-before_acc:9.4f}, {original_acc-after_acc:9.4f}\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5278080",
   "metadata": {},
   "outputs": [],
   "source": [
    " sparsity_per_layer = 0.1\n",
    "lenet5_model.to(\"cpu\")\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "# acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "# print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.to(DEVICE)\n",
    "lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=DEVICE,\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10372455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
