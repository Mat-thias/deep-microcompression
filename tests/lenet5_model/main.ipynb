{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4441fa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df77885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    BatchNorm2d,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    ReLU6,\n",
    "    MaxPool2d,\n",
    "    Flatten, \n",
    "\n",
    "    EarlyStopper,\n",
    "\n",
    "    QUANTIZATION_NONE, \n",
    "    DYNAMIC_QUANTIZATION_PER_TENSOR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = \"lenet5_state_dict.pth\"\n",
    "log_compression_details_file = \"lenet5_compression_log.csv\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n",
    "\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"../../../Datasets/\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"../../../Datasets/\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True, num_workers=os.cpu_count())\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32, shuffle=False, num_workers=os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, pad=tuple([0]*4), bias=True),\n",
    "    # BatchNorm2d(num_features=6),\n",
    "    ReLU(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    # BatchNorm2d(num_features=16),\n",
    "    ReLU(),\n",
    "\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Linear(in_features=16*5*5, out_features=84, bias=False),\n",
    "    ReLU(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b811aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model = Sequential(\n",
    "#     Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=5, pad=[2]*4, bias=False),\n",
    "#     BatchNorm2d(num_features=3),\n",
    "#     ReLU6(),\n",
    "#     Flatten(),\n",
    "#     Linear(in_features=3*6*6, out_features=10, bias=True)\n",
    "# ).to(DEVICE)\n",
    "\n",
    "# accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True), strict=False)\n",
    "    \n",
    "except (RuntimeError, FileNotFoundError) as e:\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-7,\n",
    "        mode=\"min\",\n",
    "        patience=2,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 100, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\" : accuracy_fun},\n",
    "        callbacks=[early_stopper],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 130.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.21, 148088)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "# print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n",
    "# print(lenet5_mcu_model.test(device=DEVICE))\n",
    "original_acc, original_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad66a75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number 0 ->  sparsity = 0.5, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 115.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 4 acc = 16.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [03:54<01:57, 23.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.040816055391232176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 141.48it/s]\n",
      "  1%|          | 1/100 [03:59<6:35:49, 239.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.00, bitwidth = 4 acc = 54.9100\n",
      "sample number 1 ->  sparsity = 0.8, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 137.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 1, bitwidth = 8 acc = 14.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [05:05<00:00, 20.37s/it]\n",
      "100%|██████████| 313/313 [00:02<00:00, 147.83it/s]\n",
      "  2%|▏         | 2/100 [09:10<7:39:23, 281.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.10, bitwidth = 8 acc = 33.9500\n",
      "sample number 2 ->  sparsity = 0.5, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 147.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.5, q_type = 1, bitwidth = 8 acc = 24.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [03:28<01:44, 20.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 6 epoch with best train_loss = 0.037477165168523785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 157.56it/s]\n",
      "  3%|▎         | 3/100 [12:43<6:44:22, 250.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.20, bitwidth = 8 acc = 58.4700\n",
      "sample number 3 ->  sparsity = 0.2, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 145.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 4 acc = 86.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:10<02:06, 21.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.004752312171971426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 159.46it/s]\n",
      "  4%|▍         | 4/100 [15:57<6:05:05, 228.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.30, bitwidth = 4 acc = 94.8000\n",
      "sample number 4 ->  sparsity = 0.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 143.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 1, bitwidth = 8 acc = 99.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [01:53<03:46, 22.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 1 epoch with best train_loss = 0.0004372085090315295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 145.16it/s]\n",
      "  5%|▌         | 5/100 [17:55<4:58:19, 188.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.40, bitwidth = 8 acc = 99.1500\n",
      "sample number 5 ->  sparsity = 0.3, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 148.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 0, bitwidth = 4 acc = 60.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:27<00:00, 17.82s/it]\n",
      "100%|██████████| 313/313 [00:01<00:00, 158.25it/s]\n",
      "  6%|▌         | 6/100 [22:27<5:39:30, 216.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.50, bitwidth = 4 acc = 99.1100\n",
      "sample number 6 ->  sparsity = 1.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 147.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 8 acc = 8.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [02:44<03:08, 23.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 3 epoch with best train_loss = 0.07187908789714177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 146.19it/s]\n",
      "  7%|▋         | 7/100 [25:16<5:11:51, 201.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.60, bitwidth = 8 acc = 12.1300\n",
      "sample number 7 ->  sparsity = 0.0, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 149.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.0, q_type = 0, bitwidth = 4 acc = 99.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [02:31<02:52, 21.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 3 epoch with best train_loss = 0.0008016392489818827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 160.68it/s]\n",
      "  8%|▊         | 8/100 [27:51<4:46:09, 186.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.70, bitwidth = 4 acc = 98.8800\n",
      "sample number 8 ->  sparsity = 0.3, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 146.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.3, q_type = 0, bitwidth = 4 acc = 60.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:21<00:00, 17.42s/it]\n",
      "100%|██████████| 313/313 [00:01<00:00, 162.64it/s]\n",
      "  9%|▉         | 9/100 [32:17<5:20:27, 211.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.80, bitwidth = 4 acc = 99.0300\n",
      "sample number 9 ->  sparsity = 0.2, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 147.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.2, q_type = 1, bitwidth = 8 acc = 93.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [02:47<02:26, 20.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 4 epoch with best train_loss = 0.0026671191372811638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 159.32it/s]\n",
      " 10%|█         | 10/100 [35:09<4:58:50, 199.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 0.90, bitwidth = 8 acc = 96.6100\n",
      "sample number 10 ->  sparsity = 1.0, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 146.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 1.0, q_type = 1, bitwidth = 8 acc = 8.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:06<02:04, 20.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.07187913657824198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 162.68it/s]\n",
      " 11%|█         | 11/100 [38:20<4:51:35, 196.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.00, bitwidth = 8 acc = 12.1400\n",
      "sample number 11 ->  sparsity = 0.7, q_type = 0, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 148.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.7, q_type = 0, bitwidth = 4 acc = 17.1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:21<00:00, 17.42s/it]\n",
      "100%|██████████| 313/313 [00:01<00:00, 160.81it/s]\n",
      " 12%|█▏        | 12/100 [42:45<5:19:03, 217.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.10, bitwidth = 4 acc = 97.3500\n",
      "sample number 12 ->  sparsity = 0.6, q_type = 1, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 146.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.6, q_type = 1, bitwidth = 8 acc = 22.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [03:05<02:03, 20.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 5 epoch with best train_loss = 0.03806790921588739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 156.14it/s]\n",
      " 13%|█▎        | 13/100 [45:55<5:03:07, 209.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.20, bitwidth = 8 acc = 58.4600\n",
      "sample number 13 ->  sparsity = 0.4, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 149.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 4 acc = 47.4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [03:44<01:21, 20.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 7 epoch with best train_loss = 0.02700058546513319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 162.04it/s]\n",
      " 14%|█▍        | 14/100 [49:43<5:07:59, 214.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.30, bitwidth = 4 acc = 70.3800\n",
      "sample number 14 ->  sparsity = 0.4, q_type = 1, bitwidth = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 132.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.4, q_type = 1, bitwidth = 4 acc = 47.5200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [04:21<01:05, 21.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping Training of Sequential with at 8 epoch with best train_loss = 0.02689203179329634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 159.43it/s]\n",
      " 15%|█▌        | 15/100 [54:09<5:26:07, 230.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training, sparsity = 1.40, bitwidth = 4 acc = 70.6700\n",
      "sample number 15 ->  sparsity = 0.8, q_type = 0, bitwidth = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:02<00:00, 144.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, sparsity = 0.8, q_type = 0, bitwidth = 8 acc = 14.3800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [03:22<01:13, 18.40s/it]\n",
      " 15%|█▌        | 15/100 [57:33<5:26:12, 230.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     55\u001b[39m optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=\u001b[32m1.e-3\u001b[39m)\n\u001b[32m     56\u001b[39m lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, patience=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43mcompressed_lenet5_mcu_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmnist_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizion_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmnist_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43macc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_fun\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*\u001b[32m100\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAfter training, sparsity = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi/RANGE\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, bitwidth = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mafter_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/models/sequential.py:151\u001b[39m, in \u001b[36mSequential.fit\u001b[39m\u001b[34m(self, train_dataloader, epochs, criterion_fun, optimizer_fun, lr_scheduler, validation_dataloader, metrics, verbose, compression_config, callbacks, device)\u001b[39m\n\u001b[32m    149\u001b[39m y_pred = \u001b[38;5;28mself\u001b[39m(X)\n\u001b[32m    150\u001b[39m loss = criterion_fun(y_pred, y_true)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m train_loss += loss.item()\n\u001b[32m    153\u001b[39m train_data_len += X.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/_tensor.py:592\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m    590\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._tensor_str._str(\u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents)\n\u001b[32m--> \u001b[39m\u001b[32m592\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbackward\u001b[39m(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient=\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph=\u001b[38;5;28;01mNone\u001b[39;00m, create_graph=\u001b[38;5;28;01mFalse\u001b[39;00m, inputs=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    594\u001b[39m ):\n\u001b[32m    595\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[32m    596\u001b[39m \n\u001b[32m    597\u001b[39m \u001b[33;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    636\u001b[39m \u001b[33;03m            used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[32m    637\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.25\n",
    "RANGE = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(log_compression_details_file):\n",
    "    with open(log_compression_details_file, \"w\") as file:\n",
    "        file.write(f\"sparsity, quantization_type, bitwidth, size, size_ratio, before acc, after acc, before acc_drop, after acc_drop\\n\")\n",
    "        # file.write(f\"sparsity, quantizaion_type, bitwidth, before acc, after acc\\n\")\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "\n",
    "    s = random.choice([i/RANGE for i in range(0, RANGE+1, 1)])\n",
    "    q = random.choice([QUANTIZATION_NONE, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR, DYNAMIC_QUANTIZATION_PER_TENSOR])\n",
    "    b = random.choice([4, 8])\n",
    "    print(f\"sample number {i} ->  sparsity = {s}, q_type = {q}, bitwidth = {b}\")\n",
    "\n",
    "    # s = .8\n",
    "    # q = 0\n",
    "    # b = 8\n",
    "\n",
    "    compression_config = {\n",
    "        \"prune_channel\" :{\n",
    "            \"sparsity\" : s\n",
    "        },\n",
    "        \"quantization\" : {\n",
    "            \"type\" : q,\n",
    "            \"bitwidth\" : b\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    lenet5_mcu_model.cpu()\n",
    "    compressed_lenet5_mcu_model = lenet5_mcu_model.compress(compression_config, input_shape=(1,1,32,32))\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    before_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    compressed_lenet5_mcu_model.cpu()\n",
    "    size = compressed_lenet5_mcu_model.get_size_in_bits()//8\n",
    "    compressed_lenet5_mcu_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Before training, sparsity = {s}, q_type = {q}, bitwidth = {b} acc = {before_acc:.4f}\")\n",
    "\n",
    "    early_stopper = EarlyStopper(\n",
    "        metric_name=\"train_loss\",\n",
    "        min_valid_diff=1e-5,\n",
    "        mode=\"min\",\n",
    "        patience=4,\n",
    "        restore_best_state_dict=True,\n",
    "    )\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(compressed_lenet5_mcu_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    compressed_lenet5_mcu_model.fit(\n",
    "        mnist_train_loader, \n",
    "        15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        metrics={\"acc\": accuracy_fun},\n",
    "        verbose = False,\n",
    "        device=DEVICE,\n",
    "        compression_config=compression_config,\n",
    "        callbacks = [early_stopper]\n",
    "    )\n",
    "    after_acc = compressed_lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)*100\n",
    "\n",
    "    print(f\"After training, sparsity = {i/RANGE:.2f}, bitwidth = {b} acc = {after_acc:.4f}\")\n",
    "\n",
    "    with open(log_compression_details_file, \"a\") as file:\n",
    "        file.write(f\"{s}, {q}, {b}, {size}, {size/original_size*100:9.4f}, {before_acc:9.4f}, {after_acc:9.4f}, {original_acc-before_acc:9.4f}, {original_acc-after_acc:9.4f}\\n\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5278080",
   "metadata": {},
   "outputs": [],
   "source": [
    " sparsity_per_layer = 0.1\n",
    "lenet5_model.to(\"cpu\")\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "# acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "# print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.to(DEVICE)\n",
    "lenet5_mcu_model.fit(\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=DEVICE,\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10372455",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38775d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "# size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "# print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "criterion_fun = nn.CrossEntropyLoss()\n",
    "optimizion_fun = optim.Adam(lenet5_mcu_model.parameters(), lr=1.e-2)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "lenet5_mcu_model.fit(\n",
    "    # mnist_test_loader,\n",
    "    mnist_train_loader, \n",
    "    15, \n",
    "    criterion_fun, optimizion_fun, lr_scheduler,\n",
    "    validation_dataloader=mnist_test_loader, \n",
    "    metrics={\"acc\": accuracy_fun},\n",
    "    device=\"cpu\",\n",
    "    compression_aware=True\n",
    ")\n",
    "lenet5_mcu_model = lenet5_mcu_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "\n",
    "\n",
    "\n",
    "# print(lenet5_mcu_model.test())\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "# lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df781286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
