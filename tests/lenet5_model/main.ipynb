{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4441fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df77885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"/home/matthias/Documents/EmbeddedAI/deep-microcompression/\")\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from development import (\n",
    "    Sequential,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    ReLU,\n",
    "    MaxPool2d,\n",
    "    Flatten\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "090b93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lenet5_file = f\"lenet5_state_dict_{DEVICE}.pth\"\n",
    "\n",
    "LUCKY_NUMBER = 25\n",
    "torch.manual_seed(LUCKY_NUMBER)\n",
    "torch.random.manual_seed(LUCKY_NUMBER)\n",
    "torch.cuda.manual_seed(LUCKY_NUMBER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4fe7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3b4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomCrop((24, 24)),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\"./datasets\", train=True, download=True, transform=data_transform)\n",
    "mnist_test_dataset = datasets.MNIST(\"./datasets\", train=False, download=True, transform=data_transform)\n",
    "\n",
    "mnist_train_loader = data.DataLoader(mnist_train_dataset, batch_size=32, shuffle=True)\n",
    "mnist_test_loader = data.DataLoader(mnist_test_dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "754a2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = Sequential(\n",
    "    Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Linear(in_features=16*5*5, out_features=84, bias=True),\n",
    "    ReLU(),\n",
    "    Linear(in_features=84, out_features=10, bias=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "accuracy_fun = lambda y_pred, y_true: (y_pred.argmax(dim=1) == y_true).sum().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "540fd9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # raise RuntimeError\n",
    "    lenet5_model.load_state_dict(torch.load(lenet5_file, weights_only=True))\n",
    "    \n",
    "except (RuntimeError, FileNotFoundError):\n",
    "\n",
    "    criterion_fun = nn.CrossEntropyLoss()\n",
    "    optimizion_fun = optim.Adam(lenet5_model.parameters(), lr=1.e-3)\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizion_fun, mode=\"min\", patience=2)\n",
    "\n",
    "    lenet5_model.fit(\n",
    "        mnist_train_loader, 15, \n",
    "        criterion_fun, optimizion_fun, lr_scheduler,\n",
    "        validation_dataloader=mnist_test_loader, \n",
    "        device=DEVICE\n",
    "    )\n",
    "    torch.save(lenet5_model.state_dict(), lenet5_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72ae4482",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original model accuracy is 100.00% with size 148424 bytes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "original_acc = lenet5_model.evaluate(mnist_test_loader, accuracy_fun, device=DEVICE)\n",
    "original_size = lenet5_model.get_size_in_bits()//8\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ec3dd",
   "metadata": {},
   "source": [
    "## Original Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db4f01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original model accuracy is 100.00% with size 148424 bytes.\n",
      "tensor([[ -7.0936,   7.9878,  -6.0555,  -9.2409,  -2.5021,  -3.0447,  -8.0069,\n",
      "          -6.5767,  -2.5293, -10.4348]])\n"
     ]
    }
   ],
   "source": [
    "lenet5_model.cpu()\n",
    "\n",
    "lenet5_mcu_model = copy.deepcopy(lenet5_model)\n",
    "\n",
    "original_acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "original_size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The original model accuracy is {original_acc*100:.2f}% with size {original_size} bytes.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d6090d",
   "metadata": {},
   "source": [
    "## Pruned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a394923",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5278080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.1 accuracy is 96.88%.\n",
      "The accurancy drop is 3.12% and size drop is 21.90%.\n",
      "tensor([[-6.8226,  6.4594, -5.5754, -9.7343,  0.9674, -4.1610, -6.0104, -7.8067,\n",
      "         -2.1789, -7.4688]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.1\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2579d8a",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10372455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.2 accuracy is 96.88%.\n",
      "The accurancy drop is 3.12% and size drop is 34.54%.\n",
      "tensor([[ -6.3855,   6.5384,  -5.1989, -10.1023,   0.5934,  -4.6097,  -5.1582,\n",
      "          -7.9441,  -2.1744,  -8.1987]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.2\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c87dc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4454d5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.3 accuracy is 87.50%.\n",
      "The accurancy drop is 12.50% and size drop is 51.22%.\n",
      "tensor([[ -2.8619,   0.3677,  -7.5608, -13.8715,  -0.3558,   0.9099,   0.9218,\n",
      "          -7.6484,  -2.0629,  -6.2257]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.3\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9eaed9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.4 accuracy is 84.38%.\n",
      "The accurancy drop is 15.62% and size drop is 61.80%.\n",
      "tensor([[  0.1158,  -0.4338,  -9.8758, -11.9314,  -2.4157,   0.5015,   0.3331,\n",
      "          -6.9573,  -1.9771,  -5.5160]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.4\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3248ecc",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e94f8c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.5 accuracy is 53.12%.\n",
      "The accurancy drop is 46.88% and size drop is 74.24%.\n",
      "tensor([[-0.4509, -5.8119, -5.9063, -4.8622, -2.8870,  0.5381,  0.7379, -5.9212,\n",
      "         -1.1492, -1.9270]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.5\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875126de",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3d7745d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.6 accuracy is 56.25%.\n",
      "The accurancy drop is 43.75% and size drop is 81.29%.\n",
      "tensor([[-1.2993, -4.6259, -5.7292, -2.7742, -2.3246,  0.2928,  1.6027, -6.0664,\n",
      "         -1.4219, -1.5903]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.6\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b643f",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38775d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.7 accuracy is 9.38%.\n",
      "The accurancy drop is 90.62% and size drop is 89.98%.\n",
      "tensor([[ 0.2819, -1.0298, -2.0192, -0.5093, -3.0721, -0.1845, -0.5431, -1.7243,\n",
      "         -0.5745, -0.7265]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.7\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f39acf9",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b46c36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.8 accuracy is 15.62%.\n",
      "The accurancy drop is 84.38% and size drop is 94.20%.\n",
      "tensor([[-0.2637, -1.9515, -2.3809, -0.2891, -2.7938,  0.1997, -0.4580, -1.9208,\n",
      "          1.2074,  0.3487]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.8\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e19a8",
   "metadata": {},
   "source": [
    "### sparsity_per_layer = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f94a2230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.9 accuracy is 0.00%.\n",
      "The accurancy drop is 100.00% and size drop is 98.28%.\n",
      "tensor([[-0.0228, -0.0563, -0.0336, -0.0563,  0.0521, -0.1073, -0.2085,  0.1049,\n",
      "          0.3267, -0.0480]])\n"
     ]
    }
   ],
   "source": [
    "sparsity_per_layer = 0.9\n",
    "lenet5_mcu_model = lenet5_model.prune_channel(sparsity_per_layer)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The pruned model with sparsity {sparsity_per_layer} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0e009",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa51868",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "996f3f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 8 accuracy is 100.00%.\n",
      "The accurancy drop is 0.00% and size drop is 74.75%.\n",
      "tensor([[ -7.1223,   8.0149,  -5.9762,  -9.1589,  -2.5781,  -3.0766,  -7.8516,\n",
      "          -6.5813,  -2.4182, -10.5235]])\n"
     ]
    }
   ],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4a4bb",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a642527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 4 accuracy is 100.00%.\n",
      "The accurancy drop is 0.00% and size drop is 87.37%.\n",
      "tensor([[-6.4828,  8.1723, -5.1209, -6.9938, -1.5367, -3.8607, -8.3492, -5.2086,\n",
      "         -1.9306, -7.5333]])\n"
     ]
    }
   ],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603123d",
   "metadata": {},
   "source": [
    "## Dynamic Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745ef4fd",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2f427d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 8 accuracy is 100.00%.\n",
      "The accurancy drop is -3.12% and size drop is 74.45%.\n",
      "tensor([[ -6.6999, -11.5344,  -7.1422,   4.7903, -12.2799,   3.7702, -11.3912,\n",
      "          -6.2070,  -0.5821,  -2.5629]])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'layer_def' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe accurancy drop is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(original_acc\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39macc)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m% and size drop is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(original_size\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39msize)/original_size*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(lenet5_mcu_model.test())\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mlenet5_mcu_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlenet5_mcu_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Arduino Nano 33 BLE/src/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./Arduino Nano 33 BLE/include/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m lenet5_mcu_model.convert_to_c(var_name=\u001b[33m\"\u001b[39m\u001b[33mlenet5_mcu_model\u001b[39m\u001b[33m\"\u001b[39m, src_dir=\u001b[33m\"\u001b[39m\u001b[33m./HP HP Pavilion Laptop 15-cs3xxx/src/\u001b[39m\u001b[33m\"\u001b[39m, include_dir=\u001b[33m\"\u001b[39m\u001b[33m./HP HP Pavilion Laptop 15-cs3xxx/include/\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/models/sequential.py:695\u001b[39m, in \u001b[36mSequential.convert_to_c\u001b[39m\u001b[34m(self, var_name, src_dir, include_dir)\u001b[39m\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[33m\"\u001b[39m\u001b[33mconvert_to_c\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    694\u001b[39m     layers_def += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    &\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_header, layer_def, layer_param_def = \u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    696\u001b[39m     layers_header += layer_header\n\u001b[32m    697\u001b[39m     param_definition_file += layer_param_def\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/EmbeddedAI/deep-microcompression/tests/lenet5_model/../../development/layers/conv.py:485\u001b[39m, in \u001b[36mConv2d.convert_to_c\u001b[39m\u001b[34m(self, var_name)\u001b[39m\n\u001b[32m    474\u001b[39m     layer_def = (\n\u001b[32m    475\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_channel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    476\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_row_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_col_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_channel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    480\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(int32_t*)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_bias, *(float*)\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_bias_scale);\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    481\u001b[39m     )\n\u001b[32m    483\u001b[39m layer_header += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mextern \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m layer_header, \u001b[43mlayer_def\u001b[49m, layer_param_def\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'layer_def' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfec219",
   "metadata": {},
   "source": [
    "## Static Quantized Per Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33273c45",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df781286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 8 accuracy is 100.00%.\n",
      "The accurancy drop is 0.00% and size drop is 74.74%.\n",
      "tensor([[-34,  63, -27, -46,  -5,  -8, -39, -31,  -3, -55]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5775f",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f229a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 4 accuracy is 100.00%.\n",
      "The accurancy drop is 0.00% and size drop is 87.35%.\n",
      "tensor([[-2,  6, -2, -4,  1, -1, -2, -1, -1, -3]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8857b",
   "metadata": {},
   "source": [
    "## Static Quantized Per Channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7f2357",
   "metadata": {},
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 8\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701fa6e",
   "metadata": {},
   "source": [
    "### 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwidth = 4\n",
    "lenet5_mcu_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "acc = lenet5_mcu_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "size = lenet5_mcu_model.get_size_in_bits()//8\n",
    "print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "print(lenet5_mcu_model.test())\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./Arduino Nano 33 BLE/src/\", include_dir=\"./Arduino Nano 33 BLE/include/\")\n",
    "lenet5_mcu_model.convert_to_c(var_name=\"lenet5_mcu_model\", src_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/src/\", include_dir=\"./HP HP Pavilion Laptop 15-cs3xxx/include/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca80dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4e7e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9845a148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade4f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c386004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 39.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.0 accuracy is 99.08%.\n",
      "The accurancy drop is 0.09% and size drop is 0.00%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.1 accuracy is 95.39%.\n",
      "The accurancy drop is 3.78% and size drop is 21.90%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.2 accuracy is 93.77%.\n",
      "The accurancy drop is 5.40% and size drop is 34.54%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 48.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.3 accuracy is 77.89%.\n",
      "The accurancy drop is 21.28% and size drop is 51.22%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.4 accuracy is 70.16%.\n",
      "The accurancy drop is 29.01% and size drop is 61.80%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.5 accuracy is 49.64%.\n",
      "The accurancy drop is 49.53% and size drop is 74.24%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 48.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.6 accuracy is 38.89%.\n",
      "The accurancy drop is 60.28% and size drop is 81.29%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.7 accuracy is 6.58%.\n",
      "The accurancy drop is 92.59% and size drop is 89.98%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.8 accuracy is 13.32%.\n",
      "The accurancy drop is 85.85% and size drop is 94.20%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 51.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model with sparsity 0.9 accuracy is 9.38%.\n",
      "The accurancy drop is 89.79% and size drop is 98.28%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 8 accuracy is 99.11%.\n",
      "The accurancy drop is 0.06% and size drop is 74.75%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 7 accuracy is 99.13%.\n",
      "The accurancy drop is 0.04% and size drop is 74.75%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 6 accuracy is 99.18%.\n",
      "The accurancy drop is -0.01% and size drop is 74.75%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 5 accuracy is 99.04%.\n",
      "The accurancy drop is 0.13% and size drop is 74.75%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 4 accuracy is 98.80%.\n",
      "The accurancy drop is 0.37% and size drop is 87.37%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 3 accuracy is 92.91%.\n",
      "The accurancy drop is 6.26% and size drop is 87.37%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:41<00:00,  1.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 2 accuracy is 9.74%.\n",
      "The accurancy drop is 89.43% and size drop is 93.68%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per tensor model with bitwidth 1 accuracy is 9.80%.\n",
      "The accurancy drop is 89.37% and size drop is 96.83%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 8 accuracy is 99.08%.\n",
      "The accurancy drop is 0.09% and size drop is 74.45%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 7 accuracy is 99.08%.\n",
      "The accurancy drop is 0.09% and size drop is 74.45%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 46.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 6 accuracy is 99.14%.\n",
      "The accurancy drop is 0.03% and size drop is 74.45%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 47.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 5 accuracy is 98.96%.\n",
      "The accurancy drop is 0.21% and size drop is 74.45%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 49.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 4 accuracy is 98.95%.\n",
      "The accurancy drop is 0.22% and size drop is 87.07%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 44.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 3 accuracy is 94.07%.\n",
      "The accurancy drop is 5.10% and size drop is 87.07%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 47.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 2 accuracy is 16.01%.\n",
      "The accurancy drop is 83.16% and size drop is 93.38%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 50.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dynamic quantized per channel model with bitwidth 1 accuracy is 9.80%.\n",
      "The accurancy drop is 89.37% and size drop is 96.53%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 45.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 8 accuracy is 99.17%.\n",
      "The accurancy drop is 0.00% and size drop is 74.74%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 44.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 7 accuracy is 99.05%.\n",
      "The accurancy drop is 0.12% and size drop is 74.74%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 6 accuracy is 99.06%.\n",
      "The accurancy drop is 0.11% and size drop is 74.74%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 5 accuracy is 98.78%.\n",
      "The accurancy drop is 0.39% and size drop is 74.74%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 4 accuracy is 98.00%.\n",
      "The accurancy drop is 1.17% and size drop is 87.35%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 3 accuracy is 59.10%.\n",
      "The accurancy drop is 40.07% and size drop is 87.35%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 2 accuracy is 9.80%.\n",
      "The accurancy drop is 89.37% and size drop is 93.66%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per tensor model with bitwidth 1 accuracy is 9.80%.\n",
      "The accurancy drop is 89.37% and size drop is 96.81%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 40.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 8 accuracy is 99.08%.\n",
      "The accurancy drop is 0.09% and size drop is 74.43%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 7 accuracy is 99.08%.\n",
      "The accurancy drop is 0.09% and size drop is 74.43%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 6 accuracy is 99.01%.\n",
      "The accurancy drop is 0.16% and size drop is 74.43%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 41.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 5 accuracy is 98.83%.\n",
      "The accurancy drop is 0.34% and size drop is 74.43%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 4 accuracy is 98.28%.\n",
      "The accurancy drop is 0.89% and size drop is 87.05%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 42.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 3 accuracy is 85.02%.\n",
      "The accurancy drop is 14.15% and size drop is 87.05%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:07<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 2 accuracy is 9.79%.\n",
      "The accurancy drop is 89.38% and size drop is 93.36%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:06<00:00, 44.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The static quantized per channel model with bitwidth 1 accuracy is 9.80%.\n",
      "The accurancy drop is 89.37% and size drop is 96.51%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# lenet5_model.cpu()\n",
    "\n",
    "# # PRUNED MODEL\n",
    "# pruned_sparsity = [i/10 for i in range(10)]\n",
    "# for sparsity in pruned_sparsity:\n",
    "#     pruned_model = lenet5_model.prune_channel(sparsity)\n",
    "#     acc = pruned_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = pruned_model.get_size_in_bits()//8\n",
    "#     print(f\"The pruned model with sparsity {sparsity} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "# quantization_bitwidth = [i for i in range(8, 0, -1)]\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_tensor_model = lenet5_model.dynamic_quantize_per_tensor(bitwidth)\n",
    "#     acc = dynamic_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # DYNAMIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     dynamic_quantized_per_channel_model = lenet5_model.dynamic_quantize_per_channel(bitwidth)\n",
    "#     acc = dynamic_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = dynamic_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The dynamic quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_tensor_model = lenet5_model.static_quantize_per_tensor(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_tensor_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_tensor_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per tensor model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n",
    "\n",
    "# # STATIC QUANTIZED MODEL PER TERSON\n",
    "# for bitwidth in quantization_bitwidth:\n",
    "#     static_quantized_per_channel_model = lenet5_model.static_quantize_per_channel(next(iter(mnist_test_loader))[0], bitwidth)\n",
    "#     acc = static_quantized_per_channel_model.evaluate(mnist_test_loader, accuracy_fun)\n",
    "#     size = static_quantized_per_channel_model.get_size_in_bits()//8\n",
    "#     print(f\"The static quantized per channel model with bitwidth {bitwidth} accuracy is {acc*100:.2f}%.\")\n",
    "#     print(f\"The accurancy drop is {(original_acc - acc)*100:.2f}% and size drop is {(original_size - size)/original_size*100:.2f}%.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5deac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
